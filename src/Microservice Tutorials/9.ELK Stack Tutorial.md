# Complete ELK Stack Tutorial: Monitoring Spring Boot Microservices

## A Comprehensive Guide with Real-World Examples and Visual Analogies

----------

## Why is Monitoring of an Application Becoming More Important?

### Real-World Case Study: The E-Commerce Black Friday Disaster

**Scenario:** In November 2019, a major e-commerce company experienced a catastrophic failure during Black Friday sales. Their checkout service crashed, causing an estimated $2.3 million in lost revenue over 4 hours.

**What went wrong?**

-   No centralized logging system
-   Logs scattered across 50+ microservices
-   Took 3 hours to identify the root cause
-   Had to manually SSH into each server to check logs

**The Problem They Faced:**

```
Traditional Approach (Without Monitoring):
Server 1 → Local Log File
Server 2 → Local Log File
Server 3 → Local Log File
...
Server 50 → Local Log File

Problem: How do you find which server caused the issue?
```

### Memory Visualization: The Library Analogy

**Imagine your application logs as books in a library:**

**Without ELK (Chaos):**
- Books scattered randomly across 50 different rooms
- No catalog system
- To find information, you must physically check each room
- Takes hours to find a single piece of information

**With ELK (Organized):**
- All books cataloged in a central system
- Search by keyword, date, author instantly
- Find information in seconds
- Correlate information across multiple books simultaneously

---

## What is ELK Stack?

### Theory & Concept

**ELK** is an acronym for three open-source projects:
- **E**lasticsearch
- **L**ogstash
- **K**ibana

### The Restaurant Analogy

Think of ELK Stack as a restaurant operation:
```
┌─────────────────────────────────────────────────┐
│                  RESTAURANT                      │
├─────────────────────────────────────────────────┤
│                                                  │
│  LOGSTASH (Kitchen Staff - Preparation)          │
│  ↓                                               │
│  • Receives raw ingredients (logs)               │
│  • Cleans and prepares them (parsing)            │
│  • Adds seasoning (enrichment)                   │
│  • Organizes on plates (formatting)              │
│                                                  │
│  ELASTICSEARCH (Storage & Retrieval System)      │
│  ↓                                               │
│  • Smart refrigerator that organizes food        │
│  • Knows exactly where everything is             │
│  • Can retrieve any item in milliseconds         │
│  • Cross-references ingredients instantly        │
│                                                  │
│  KIBANA (Dining Area & Menu)                     │
│  ↓                                               │
│  • Beautiful presentation of dishes              │
│  • Visual menu to browse offerings               │
│  • Customizable based on preferences             │
│  • Interactive experience for customers          │
│                                                  │
└─────────────────────────────────────────────────┘
```

### Technical Deep Dive

#### 1. **Logstash** (Data Collection & Processing Engine)

**What it does:**
- Collects logs from multiple sources
- Parses and transforms log data
- Filters and enriches data
- Sends processed data to Elasticsearch

**Memory Visualization: The Mail Sorting Center**
```
Raw Logs (Incoming Mail)
        ↓
    [LOGSTASH]
        ↓
┌──────────────────┐
│  INPUT PLUGINS   │ ← Receive data (File, TCP, HTTP, etc.)
└────────┬─────────┘
         ↓
┌──────────────────┐
│ FILTER PLUGINS   │ ← Parse, transform, enrich
│  - Grok          │   (Like sorting mail by type)
│  - Mutate        │
│  - Date          │
└────────┬─────────┘
         ↓
┌──────────────────┐
│ OUTPUT PLUGINS   │ ← Send to destination
└──────────────────┘
         ↓
    Elasticsearch
```

#### 2. **Elasticsearch** (Search & Analytics Engine)

**What it does:**
- Stores logs in a distributed manner
- Indexes data for fast searching
- Performs complex queries and aggregations
- Scales horizontally

**Technical Architecture:**
```
┌─────────────────────────────────────────┐
│         ELASTICSEARCH CLUSTER            │
├─────────────────────────────────────────┤
│                                          │
│  ┌──────────┐  ┌──────────┐  ┌────────┐│
│  │  Node 1  │  │  Node 2  │  │ Node 3 ││
│  │ (Master) │  │  (Data)  │  │ (Data) ││
│  └──────────┘  └──────────┘  └────────┘│
│                                          │
│  Indices (Databases):                    │
│  ┌─────────────────────────────────────┐│
│  │ logs-2025.11.01                     ││
│  │  ├─ Shard 1 (Primary)               ││
│  │  ├─ Shard 1 (Replica)               ││
│  │  ├─ Shard 2 (Primary)               ││
│  │  └─ Shard 2 (Replica)               ││
│  └─────────────────────────────────────┘│
│                                          │
└─────────────────────────────────────────┘
```

**The Library Index Card Analogy:**
- Each log entry is like a book
- Elasticsearch creates an "index card" for every word in every log
- When you search, it looks up the index cards (instant)
- Rather than reading every book (slow)

#### 3. **Kibana** (Visualization & Dashboard)

**What it does:**
- Visualizes Elasticsearch data
- Creates interactive dashboards
- Provides search interface
- Generates reports and alerts

**Dashboard Components:**
```
┌─────────────────────────────────────────────┐
│            KIBANA DASHBOARD                  │
├─────────────────────────────────────────────┤
│                                              │
│  [Line Chart]    [Pie Chart]   [Heat Map]   │
│  Response Times  Error Types   API Usage    │
│                                              │
│  [Data Table]                                │
│  Recent Error Logs                           │
│                                              │
│  [Metric Visualization]                      │
│  Total Requests: 1.2M                        │
│  Error Rate: 0.03%                           │
│                                              │
└─────────────────────────────────────────────┘
```

---

## Why ELK Stack?

### Comparative Analysis

#### Before ELK:
```
Problems:
1. Log Fragmentation
   ├─ Microservice A → app-a.log
   ├─ Microservice B → app-b.log
   ├─ Microservice C → app-c.log
   └─ Database Server → db.log

2. Manual Investigation
   ├─ SSH into each server
   ├─ grep through massive files
   ├─ No correlation between services
   └─ Takes hours to debug

3. No Real-time Monitoring
   ├─ Discover issues after customers complain
   ├─ No proactive alerting
   └─ No visibility into system health

4. Storage Issues
   ├─ Logs fill up disk space
   ├─ Old logs deleted to save space
   └─ Historical data lost
```

#### After ELK:
```
Solutions:
1. Centralized Logging
   All Services → Logstash → Elasticsearch
   
2. Instant Search & Analysis
   ├─ Search across all services simultaneously
   ├─ Correlate logs by request ID
   ├─ Filter by time, service, error type
   └─ Find root cause in minutes

3. Real-time Monitoring
   ├─ Live dashboards
   ├─ Automated alerts
   ├─ Proactive issue detection
   └─ Know about problems before users do

4. Scalable Storage
   ├─ Distributed storage
   ├─ Automatic retention policies
   ├─ Compressed storage
   └─ Historical data preserved
```

### Real-World Benefits (Case Study Continuation)

**After implementing ELK, the e-commerce company achieved:**

| Metric | Before ELK | After ELK | Improvement |
|--------|-----------|-----------|-------------|
| Mean Time to Detection (MTTD) | 45 minutes | 2 minutes | 95.6% faster |
| Mean Time to Resolution (MTTR) | 3 hours | 15 minutes | 91.7% faster |
| System Uptime | 98.5% | 99.95% | 0.45% increase |
| Lost Revenue (per incident) | $2.3M | $50K | 97.8% reduction |

---

## What is ELK Stack Used For?

### 1. Application Performance Monitoring (APM)

**Example Scenario: E-commerce Website**
```
User Journey Tracking:
┌────────────────────────────────────────────────┐
│ User clicks "Buy Now"                          │
│   ↓                                            │
│ [API Gateway] - 5ms                            │
│   ↓                                            │
│ [Auth Service] - 15ms                          │
│   ↓                                            │
│ [Product Service] - 120ms ⚠️ SLOW!            │
│   ↓                                            │
│ [Payment Service] - 250ms                      │
│   ↓                                            │
│ [Order Service] - 30ms                         │
│                                                 │
│ Total: 420ms                                    │
└────────────────────────────────────────────────┘

ELK Dashboard Shows:
- Which service is slow
- When it started being slow
- How many users affected
- Correlation with deployments
```

### 2. Security & Audit Logging

**Example: Banking Application**
```
Security Events Tracked:
├─ Failed Login Attempts
│  └─ IP: 192.168.1.100 - 5 failures in 1 minute ⚠️
│
├─ Unusual Transaction Patterns
│  └─ User transferred $50K to new account at 3 AM ⚠️
│
├─ API Access Patterns
│  └─ 1000 requests/sec from single IP (DDoS?) ⚠️
│
└─ Data Access Logs
   └─ Admin accessed customer SSN records
```

### 3. Business Analytics

**Example: Understanding User Behavior**
```
Kibana Dashboard Metrics:
┌─────────────────────────────────────┐
│  Peak Usage Hours: 8-10 PM          │
│  Most Popular Products: [Chart]     │
│  Conversion Funnel:                 │
│    100% - Homepage                  │
│     75% - Product Page              │
│     30% - Add to Cart               │
│     12% - Checkout                  │
│      8% - Purchase Complete         │
│                                     │
│  Drop-off Analysis:                 │
│  • 45% abandon at payment page      │
│  • Average time on cart: 2m 30s    │
└─────────────────────────────────────┘
```

### 4. Infrastructure Monitoring

**Example: Microservices Health**
```
System Health Dashboard:
┌──────────────────────────────────────┐
│  CPU Usage:        45% ✓              │
│  Memory Usage:     82% ⚠️             │
│  Disk I/O:         Normal ✓           │
│  Network Traffic:  High ⚠️            │
│                                       │
│  Service Status:                      │
│  ✓ Auth Service    (100% uptime)     │
│  ✓ Product Service (100% uptime)     │
│  ⚠️ Payment Service (2 failures/hr)   │
│  ✓ Order Service   (100% uptime)     │
└──────────────────────────────────────┘
```

### 5. Error Tracking & Debugging

**Example: Debugging Production Issues**
```
Error Investigation Flow:

1. Alert Triggered:
   "NullPointerException in Payment Service"

2. Kibana Query:
   service:"payment-service" AND level:"ERROR"

3. Found Error Pattern:
   ┌─────────────────────────────────────────┐
   │ 2025-11-01 14:35:21 ERROR               │
   │ NullPointerException at line 145        │
   │ RequestID: abc-123-xyz                  │
   │ User: user@example.com                  │
   │ Payment Method: null ← ROOT CAUSE       │
   └─────────────────────────────────────────┘

4. Correlate with other services:
   Search by RequestID "abc-123-xyz"
   
   Auth Service: ✓ User authenticated
   Product Service: ✓ Product available
   Cart Service: ⚠️ Payment method not saved
   Payment Service: ✗ Received null value

5. Root Cause Identified:
   Cart service failed to save payment method
   due to database connection timeout
```

---

## How to Download and Install ELK Stack

### System Requirements
```
Minimum Requirements:
├─ RAM: 4GB (8GB recommended)
├─ Disk Space: 10GB free
├─ Java: JDK 11 or higher
└─ OS: Windows, Linux, or macOS

Recommended for Production:
├─ RAM: 16GB+
├─ Disk Space: 50GB+ SSD
├─ CPU: 4+ cores
└─ Network: 1Gbps
```

### Prerequisites Installation

**Step 1: Install Java**

bash

```bash
# Check if Java is installed
java -version

# If not installed:

# For Ubuntu/Debian:
sudo apt update
sudo apt install openjdk-11-jdk

# For CentOS/RHEL:
sudo yum install java-11-openjdk

# For macOS:
brew install openjdk@11

# For Windows:
# Download from: https://www.oracle.com/java/technologies/downloads/
```

**Step 2: Set JAVA_HOME**

bash

```bash
# Linux/macOS - Add to ~/.bashrc or ~/.zshrc
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk
export PATH=$JAVA_HOME/bin:$PATH

# Windows - Set Environment Variable
# JAVA_HOME = C:\Program Files\Java\jdk-11
# Add to PATH: %JAVA_HOME%\bin
```

---

## 1) Elasticsearch Installation

### Understanding Elasticsearch Architecture Before Installation
```
Elasticsearch Node Types:
┌────────────────────────────────────────┐
│  Master Node:                          │
│  • Manages cluster state               │
│  • Creates/deletes indices             │
│  • Tracks node membership              │
├────────────────────────────────────────┤
│  Data Node:                            │
│  • Stores actual data                  │
│  • Executes search queries             │
│  • Performs aggregations               │
├────────────────────────────────────────┤
│  Ingest Node:                          │
│  • Pre-processes documents             │
│  • Applies transformations             │
└────────────────────────────────────────┘

For our tutorial: Single node (all roles)
```

### Download Elasticsearch

**Version Selection:**
- Latest Stable: 8.x (as of 2025)
- We'll use: 8.11.0 (stable)

**Download Links:**
```
Official Website: https://www.elastic.co/downloads/elasticsearch

Direct Downloads:
├─ Linux (DEB): elasticsearch-8.11.0-amd64.deb
├─ Linux (RPM): elasticsearch-8.11.0-x86_64.rpm
├─ Linux (TAR): elasticsearch-8.11.0-linux-x86_64.tar.gz
├─ Windows (ZIP): elasticsearch-8.11.0-windows-x86_64.zip
└─ macOS (TAR): elasticsearch-8.11.0-darwin-x86_64.tar.gz
```

### Installation Steps

#### **Linux Installation:**

bash

```bash
# Method 1: Using DEB package (Ubuntu/Debian)
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.11.0-amd64.deb
sudo dpkg -i elasticsearch-8.11.0-amd64.deb

# Method 2: Using RPM package (CentOS/RHEL)
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.11.0-x86_64.rpm
sudo rpm -i elasticsearch-8.11.0-x86_64.rpm

# Method 3: Using TAR archive (Any Linux)
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.11.0-linux-x86_64.tar.gz
tar -xzf elasticsearch-8.11.0-linux-x86_64.tar.gz
cd elasticsearch-8.11.0/
```

#### **Windows Installation:**

cmd

```cmd
# Download ZIP file
# Extract to: C:\elasticsearch-8.11.0\

# Navigate to directory
cd C:\elasticsearch-8.11.0\
```

#### **macOS Installation:**

bash

```bash
# Method 1: Using Homebrew
brew tap elastic/tap
brew install elastic/tap/elasticsearch-full

# Method 2: Manual installation
curl -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.11.0-darwin-x86_64.tar.gz
tar -xzf elasticsearch-8.11.0-darwin-x86_64.tar.gz
cd elasticsearch-8.11.0/
```

### Configuration

**1. Configure elasticsearch.yml**

bash

```bash
# Location:
# Linux (DEB/RPM): /etc/elasticsearch/elasticsearch.yml
# Linux (TAR): elasticsearch-8.11.0/config/elasticsearch.yml
# Windows: C:\elasticsearch-8.11.0\config\elasticsearch.yml
# macOS: /usr/local/etc/elasticsearch/elasticsearch.yml
```

**Basic Configuration for Development:**

yaml

```yaml
# elasticsearch.yml

# Cluster name (identifies your cluster)
cluster.name: my-elk-cluster

# Node name (unique identifier for this node)
node.name: node-1

# Network settings
network.host: 0.0.0.0  # Listen on all interfaces
http.port: 9200         # HTTP API port
transport.port: 9300    # Inter-node communication

# Discovery settings (single-node for development)
discovery.type: single-node

# Disable security for development (NOT for production!)
xpack.security.enabled: false
xpack.security.enrollment.enabled: false
xpack.security.http.ssl.enabled: false
xpack.security.transport.ssl.enabled: false

# Memory settings
bootstrap.memory_lock: true

# Path settings
path.data: /var/lib/elasticsearch  # Data directory
path.logs: /var/log/elasticsearch  # Log directory
```

**Memory Configuration Explanation:**
```
┌──────────────────────────────────────────┐
│  JVM Heap Memory (Critical!)             │
├──────────────────────────────────────────┤
│                                          │
│  Rule of Thumb:                          │
│  • Set heap to 50% of available RAM      │
│  • Never exceed 32GB (JVM limitation)    │
│  • Leave 50% for OS file cache           │
│                                          │
│  Examples:                               │
│  8GB RAM  → 4GB heap                     │
│  16GB RAM → 8GB heap                     │
│  64GB RAM → 32GB heap (max)              │
│                                          │
└──────────────────────────────────────────┘
```

**2. Configure JVM Options:**

bash

```bash
# Edit jvm.options file
# Location: config/jvm.options

# Heap size settings
-Xms4g  # Initial heap size (4GB)
-Xmx4g  # Maximum heap size (4GB) - Must match Xms!

# GC settings (default is fine for most cases)
-XX:+UseG1GC
```

### Starting Elasticsearch

#### **Linux (System Service):**

bash

```bash
# Enable Elasticsearch to start on boot
sudo systemctl enable elasticsearch

# Start Elasticsearch
sudo systemctl start elasticsearch

# Check status
sudo systemctl status elasticsearch

# View logs
sudo journalctl -u elasticsearch -f
```

#### **Linux/macOS (Manual Start):**

bash

```bash
# Navigate to Elasticsearch directory
cd elasticsearch-8.11.0/

# Start in foreground
./bin/elasticsearch

# Start in background
./bin/elasticsearch -d -p pid

# Stop (if started in background)
pkill -F pid
```

#### **Windows:**

cmd

```cmd
# Navigate to bin directory
cd C:\elasticsearch-8.11.0\bin

# Start Elasticsearch
elasticsearch.bat

# Or install as Windows service
elasticsearch-service.bat install
elasticsearch-service.bat start
```

### Verification

**Test Elasticsearch is running:**

bash

```bash
# Basic health check
curl -X GET "localhost:9200/"

# Expected output:
{
  "name" : "node-1",
  "cluster_name" : "my-elk-cluster",
  "cluster_uuid" : "abc123...",
  "version" : {
    "number" : "8.11.0",
    "build_type" : "tar",
    "build_hash" : "...",
    "build_date" : "...",
    "build_snapshot" : false,
    "lucene_version" : "9.8.0",
    "minimum_wire_compatibility_version" : "7.17.0",
    "minimum_index_compatibility_version" : "7.0.0"
  },
  "tagline" : "You Know, for Search"
}

# Check cluster health
curl -X GET "localhost:9200/_cluster/health?pretty"

# Expected output:
{
  "cluster_name" : "my-elk-cluster",
  "status" : "green",  # green = healthy, yellow = warning, red = critical
  "timed_out" : false,
  "number_of_nodes" : 1,
  "number_of_data_nodes" : 1,
  "active_primary_shards" : 0,
  "active_shards" : 0,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
```

### Common Issues & Troubleshooting

**Issue 1: Port Already in Use**

bash

```bash
# Check what's using port 9200
sudo lsof -i :9200

# Or
netstat -tulpn | grep 9200

# Kill the process
sudo kill -9 <PID>
```

**Issue 2: Insufficient Memory**
```
Error: Java heap space

Solution:
1. Reduce heap size in jvm.options
2. Close other applications
3. Add more RAM
```

**Issue 3: Bootstrap Checks Failed**
```
Common bootstrap failures:

1. max file descriptors too low
   Solution: 
   sudo vi /etc/security/limits.conf
   Add: elasticsearch - nofile 65535

2. max virtual memory too low
   Solution:
   sudo sysctl -w vm.max_map_count=262144
   # Make permanent:
   echo "vm.max_map_count=262144" | sudo tee -a /etc/sysctl.conf

3. system call filter check failed
   Solution: Disable in elasticsearch.yml
   bootstrap.system_call_filter: false
```

---

## 2) Kibana Installation

### Understanding Kibana
```
Kibana Architecture:
┌─────────────────────────────────────────┐
│         USER BROWSER                     │
│      (JavaScript Interface)              │
└──────────────┬──────────────────────────┘
               ↓ HTTP
┌─────────────────────────────────────────┐
│       KIBANA SERVER (Node.js)            │
│  ├─ Web Server (Port 5601)               │
│  ├─ Authentication                       │
│  ├─ Visualization Engine                │
│  └─ Dashboard Management                │
└──────────────┬──────────────────────────┘
               ↓ REST API
┌─────────────────────────────────────────┐
│         ELASTICSEARCH                    │
│         (Data Storage)                   │
└─────────────────────────────────────────┘
```

### Download Kibana

**Important:** Kibana version must match Elasticsearch version!
```
Download: https://www.elastic.co/downloads/kibana

For Elasticsearch 8.11.0 → Use Kibana 8.11.0

Direct Downloads:
├─ Linux (DEB): kibana-8.11.0-amd64.deb
├─ Linux (RPM): kibana-8.11.0-x86_64.rpm
├─ Linux (TAR): kibana-8.11.0-linux-x86_64.tar.gz
├─ Windows (ZIP): kibana-8.11.0-windows-x86_64.zip
└─ macOS (TAR): kibana-8.11.0-darwin-x86_64.tar.gz
```

### Installation Steps

#### **Linux Installation:**

bash

```bash
# Method 1: DEB package (Ubuntu/Debian)
wget https://artifacts.elastic.co/downloads/kibana/kibana-8.11.0-amd64.deb
sudo dpkg -i kibana-8.11.0-amd64.deb

# Method 2: RPM package (CentOS/RHEL)
wget https://artifacts.elastic.co/downloads/kibana/kibana-8.11.0-x86_64.rpm
sudo rpm -i kibana-8.11.0-x86_64.rpm

# Method 3: TAR archive
wget https://artifacts.elastic.co/downloads/kibana/kibana-8.11.0-linux-x86_64.tar.gz
tar -xzf kibana-8.11.0-linux-x86_64.tar.gz
cd kibana-8.11.0/
```

#### **Windows Installation:**

cmd

```cmd
# Download and extract ZIP
# Extract to: C:\kibana-8.11.0\

cd C:\kibana-8.11.0\
```

#### **macOS Installation:**

bash

```bash
# Method 1: Homebrew
brew tap elastic/tap
brew install elastic/tap/kibana-full

# Method 2: Manual
curl -O https://artifacts.elastic.co/downloads/kibana/kibana-8.11.0-darwin-x86_64.tar.gz
tar -xzf kibana-8.11.0-darwin-x86_64.tar.gz
cd kibana-8.11.0/
```

### Configuration

**Edit kibana.yml:**

yaml

```yaml
# kibana.yml
# Location:
# Linux (DEB/RPM): /etc/kibana/kibana.yml
# Others: kibana-8.11.0/config/kibana.yml

# Server settings
server.port: 5601
server.host: "0.0.0.0"  # Allow external access
server.name: "my-kibana-server"

# Elasticsearch connection
elasticsearch.hosts: ["http://localhost:9200"]

# Disable security for development
xpack.security.enabled: false
xpack.encryptedSavedObjects.encryptionKey: "fhjskloppd678ehkdfdlliverpoolfcr"

# Logging
logging.dest: /var/log/kibana/kibana.log
logging.verbose: false
```

### Starting Kibana

#### **Linux (System Service):**

bash

```bash
# Enable on boot
sudo systemctl enable kibana

# Start Kibana
sudo systemctl start kibana

# Check status
sudo systemctl status kibana

# View logs
sudo journalctl -u kibana -f
```

#### **Linux/macOS (Manual):**

bash

```bash
# Foreground
./bin/kibana

# Background
nohup ./bin/kibana &
```

#### **Windows:**

cmd

```cmd
cd C:\kibana-8.11.0\bin
kibana.bat
```

### Verification

bash

```bash
# Wait 30-60 seconds for Kibana to start

# Access Kibana web interface
# Open browser: http://localhost:5601

# Check Kibana status
curl -X GET "localhost:5601/api/status"
```

**Expected Browser View:**
```
┌──────────────────────────────────────────┐
│        Kibana Home Page                  │
├──────────────────────────────────────────┤
│  [Add data] [Visualize] [Dashboard]      │
│                                          │
│  Welcome to Kibana                       │
│  Your window into the Elastic Stack     │
│                                          │
│  Getting Started:                        │
│  • Connect to Elasticsearch ✓            │
│  • Create index pattern                  │
│  • Explore your data                     │
└──────────────────────────────────────────┘
```

---

## 3) Logstash Installation

### Understanding Logstash Pipeline
```
Logstash Pipeline Architecture:
┌─────────────────────────────────────────────┐
│              INPUTS                          │
│  (Where data comes from)                     │
│  ├─ File (log files)                         │
│  ├─ TCP/UDP (network)                        │
│  ├─ HTTP (webhooks)                          │
│  ├─ Beats (log shippers)                     │
│  └─ Kafka, Redis, etc.                       │
└──────────────┬──────────────────────────────┘
               ↓
┌─────────────────────────────────────────────┐
│             FILTERS                          │
│  (How to process data)                       │
│  ├─ Grok (parse unstructured logs)           │
│  ├─ Mutate (modify fields)                   │
│  ├─ Date (parse timestamps)                  │
│  ├─ GeoIP (add location data)                │
│  └─ Drop (filter unwanted events)            │
└──────────────┬──────────────────────────────┘
               ↓
┌─────────────────────────────────────────────┐
│             OUTPUTS                          │
│  (Where to send processed data)              │
│  ├─ Elasticsearch (primary target)           │
│  ├─ File (backup)                            │
│  ├─ S3 (archival)                            │
│  └─ Monitoring tools                         │
└─────────────────────────────────────────────┘
```

### Download Logstash
```
Download: https://www.elastic.co/downloads/logstash

Version: 8.11.0 (match Elasticsearch version)

Direct Downloads:
├─ Linux (DEB): logstash-8.11.0-amd64.deb
├─ Linux (RPM): logstash-8.11.0-x86_64.rpm
├─ Linux (TAR): logstash-8.11.0-linux-x86_64.tar.gz
├─ Windows (ZIP): logstash-8.11.0-windows-x86_64.zip
└─ macOS (TAR): logstash-8.11.0-darwin-x86_64.tar.gz
```

### Installation

#### **Linux:**

bash

```bash
# DEB package
wget https://artifacts.elastic.co/downloads/logstash/logstash-8.11.0-amd64.deb
sudo dpkg -i logstash-
```


# RPM package

wget [https://artifacts.elastic.co/downloads/logstash/logstash-8.11.0-x86_64.rpm](https://artifacts.elastic.co/downloads/logstash/logstash-8.11.0-x86_64.rpm) sudo rpm -i logstash-8.11.0-x86_64.rpm

# TAR archive

wget [https://artifacts.elastic.co/downloads/logstash/logstash-8.11.0-linux-x86_64.tar.gz](https://artifacts.elastic.co/downloads/logstash/logstash-8.11.0-linux-x86_64.tar.gz) tar -xzf logstash-8.11.0-linux-x86_64.tar.gz cd logstash-8.11.0/

```

#### **Windows:**
```cmd
# Download and extract ZIP
# Extract to: C:\logstash-8.11.0\

cd C:\logstash-8.11.0\
```

#### **macOS:**
```bash
# Homebrew
brew tap elastic/tap
brew install elastic/tap/logstash-full

# Manual
curl -O https://artifacts.elastic.co/downloads/logstash/logstash-8.11.0-darwin-x86_64.tar.gz
tar -xzf logstash-8.11.0-darwin-x86_64.tar.gz
cd logstash-8.11.0/
```

### Understanding Logstash Configuration Files

**Configuration File Structure:**
```ruby
# logstash.conf structure

input {
  # Define where logs come from
}

filter {
  # Define how to process logs
}

output {
  # Define where to send processed logs
}
```

### Basic Configuration Example

**Create a simple test configuration:**
```bash
# Create config directory (if using TAR installation)
mkdir -p logstash-8.11.0/config

# Create test configuration
nano logstash-8.11.0/config/test.conf
```

**test.conf:**
```ruby
# Simple test configuration

input {
  stdin { }  # Read from keyboard input
}

filter {
  # No filters for testing
}

output {
  stdout {
    codec => rubydebug  # Print formatted output
  }
}
```

### Testing Logstash
```bash
# Test the configuration
./bin/logstash -f config/test.conf --config.test_and_exit

# Run with the test configuration
./bin/logstash -f config/test.conf

# Type something and press Enter:
# Input: Hello World
# Output will show structured JSON format
```

**Expected Output:**
```json
{
       "message" => "Hello World",
      "@version" => "1",
    "@timestamp" => 2025-11-01T10:30:00.000Z,
          "host" => "localhost",
         "event" => {
        "original" => "Hello World"
    }
}
```

### Understanding Grok Patterns (Critical for Log Parsing)

**What is Grok?**

Grok is like a "pattern matching language" that helps Logstash understand unstructured log text.

**The DNA Matching Analogy:**
```
Think of Grok as DNA pattern matching:

Raw Log (DNA sequence):
"2025-11-01 14:35:21 ERROR User login failed for john@example.com"

Grok Pattern (DNA template):
%{TIMESTAMP} %{LOGLEVEL} %{MESSAGE}

Result (Identified genes):
timestamp: "2025-11-01 14:35:21"
loglevel: "ERROR"
message: "User login failed for john@example.com"
```

**Common Grok Patterns:**
```ruby
# Built-in patterns (no need to define)

%{TIMESTAMP_ISO8601:timestamp}    # 2025-11-01T14:35:21.000Z
%{NUMBER:count}                   # Any number
%{WORD:action}                    # Single word
%{IP:client_ip}                   # IP address
%{QUOTEDSTRING:message}           # Text in quotes
%{GREEDYDATA:message}             # Everything remaining

# Example log line:
# 192.168.1.100 - - [01/Nov/2025:14:35:21] "GET /api/users HTTP/1.1" 200

# Grok pattern:
%{IP:client_ip} - - \[%{HTTPDATE:timestamp}\] "%{WORD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:http_version}" %{NUMBER:status_code}

# Result:
client_ip: "192.168.1.100"
timestamp: "01/Nov/2025:14:35:21"
method: "GET"
request: "/api/users"
http_version: "1.1"
status_code: "200"
```

**Grok Debugger Tool:**
```
Online Grok Debugger: https://grokdebugger.com
OR use Kibana's built-in Grok Debugger (Dev Tools)

This helps you test patterns before deploying!
```

### Memory Visualization: Logstash Filter Chain
```
Input Log: "2025-11-01 ERROR Payment failed for order #12345"

Filter Chain Execution:
┌────────────────────────────────────────┐
│  Step 1: GROK Filter                   │
│  Parse the log structure               │
│  ├─ timestamp: "2025-11-01"            │
│  ├─ level: "ERROR"                     │
│  └─ message: "Payment failed..."       │
└──────────────┬─────────────────────────┘
               ↓
┌────────────────────────────────────────┐
│  Step 2: MUTATE Filter                 │
│  Extract order ID from message         │
│  └─ order_id: "12345"                  │
└──────────────┬─────────────────────────┘
               ↓
┌────────────────────────────────────────┐
│  Step 3: DATE Filter                   │
│  Convert timestamp to proper format    │
│  └─ @timestamp: ISO8601 format         │
└──────────────┬─────────────────────────┘
               ↓
┌────────────────────────────────────────┐
│  Step 4: ADD_FIELD (Mutate)            │
│  Add service identifier                │
│  └─ service: "payment-service"         │
└──────────────┬─────────────────────────┘
               ↓
┌────────────────────────────────────────┐
│  Final Structured Document:            │
│  {                                     │
│    "@timestamp": "2025-11-01...",      │
│    "level": "ERROR",                   │
│    "message": "Payment failed...",     │
│    "order_id": "12345",                │
│    "service": "payment-service"        │
│  }                                     │
└────────────────────────────────────────┘
```

---

## How to Monitor Spring Boot Microservices using ELK Stack?

### Real-World Architecture Overview
```
┌──────────────────────────────────────────────────────┐
│           SPRING BOOT MICROSERVICES                   │
│  ┌──────────────┐  ┌──────────────┐  ┌────────────┐ │
│  │ User Service │  │Product Service│  │Order Service│ │
│  │  Port: 8081  │  │  Port: 8082  │  │ Port: 8083  │ │
│  └──────┬───────┘  └──────┬────────┘  └─────┬──────┘ │
│         │                  │                  │        │
│         │ Writes logs      │ Writes logs      │        │
│         ↓                  ↓                  ↓        │
│  ┌──────────────────────────────────────────────────┐ │
│  │         application.log (File System)            │ │
│  └──────────────────────────────────────────────────┘ │
└────────────────────────────┬─────────────────────────┘
                             ↓
                    ┌────────────────┐
                    │   LOGSTASH     │
                    │  Watches File  │
                    │  Parses Logs   │
                    │  Enriches Data │
                    └────────┬───────┘
                             ↓
                    ┌────────────────┐
                    │ ELASTICSEARCH  │
                    │  Indexes Data  │
                    │  Stores Logs   │
                    └────────┬───────┘
                             ↓
                    ┌────────────────┐
                    │    KIBANA      │
                    │  Visualizes    │
                    │  Searches      │
                    │  Alerts        │
                    └────────────────┘
```

---

## Step#1: Create a new Spring Boot Starter Project using STS

### Project Setup

**Option 1: Using Spring Initializr (Web)**
```
1. Visit: https://start.spring.io/

2. Configure Project:
   ├─ Project: Maven
   ├─ Language: Java
   ├─ Spring Boot: 3.1.5
   ├─ Project Metadata:
   │  ├─ Group: com.example
   │  ├─ Artifact: elk-demo
   │  ├─ Name: elk-demo
   │  ├─ Package name: com.example.elkdemo
   │  └─ Packaging: Jar
   ├─ Java: 17
   └─ Dependencies:
      ├─ Spring Web
      ├─ Spring Boot Actuator (for health endpoints)
      └─ Lombok (optional, for cleaner code)

3. Click "Generate" to download ZIP
4. Extract and import into STS/IntelliJ/Eclipse
```

**Option 2: Using Spring Tool Suite (STS)**
```
1. File → New → Spring Starter Project

2. Fill in details:
   Name: elk-demo
   Group: com.example
   Artifact: elk-demo
   Version: 0.0.1-SNAPSHOT
   Package: com.example.elkdemo
   Java Version: 17

3. Click Next → Select Dependencies:
   ✓ Spring Web
   ✓ Spring Boot Actuator
   ✓ Lombok

4. Click Finish
```

### Project Structure
```
elk-demo/
├── src/
│   ├── main/
│   │   ├── java/
│   │   │   └── com/
│   │   │       └── example/
│   │   │           └── elkdemo/
│   │   │               ├── ElkDemoApplication.java
│   │   │               ├── controller/
│   │   │               │   └── UserController.java
│   │   │               ├── model/
│   │   │               │   └── User.java
│   │   │               └── service/
│   │   │                   └── UserService.java
│   │   └── resources/
│   │       ├── application.properties
│   │       └── logback-spring.xml
│   └── test/
├── logs/
│   └── application.log (will be created)
├── pom.xml
└── README.md
```

### pom.xml Configuration
```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 
         https://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    
    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>3.1.5</version>
        <relativePath/>
    </parent>
    
    <groupId>com.example</groupId>
    <artifactId>elk-demo</artifactId>
    <version>0.0.1-SNAPSHOT</version>
    <name>elk-demo</name>
    <description>ELK Stack Demo with Spring Boot</description>
    
    <properties>
        <java.version>17</java.version>
    </properties>
    
    <dependencies>
        <!-- Spring Boot Web for REST APIs -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        
        <!-- Spring Boot Actuator for health checks -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>
        
        <!-- Logback for JSON logging (already included in Spring Boot) -->
        <dependency>
            <groupId>net.logstash.logback</groupId>
            <artifactId>logstash-logback-encoder</artifactId>
            <version>7.4</version>
        </dependency>
        
        <!-- Lombok for reducing boilerplate code -->
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <optional>true</optional>
        </dependency>
        
        <!-- Spring Boot Test -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>
    
    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
            </plugin>
        </plugins>
    </build>
</project>
```

---

## Step#2: Create a RestController

### Understanding the Components

**Memory Visualization: MVC Architecture**
```
HTTP Request Flow:
┌─────────────────────────────────────────────┐
│  CLIENT (Browser/Postman)                   │
│  Sends: GET /api/users/123                  │
└──────────────┬──────────────────────────────┘
               ↓
┌─────────────────────────────────────────────┐
│  @RestController (UserController)           │
│  • Receives HTTP request                    │
│  • Validates input                          │
│  • Logs request details                     │
└──────────────┬──────────────────────────────┘
               ↓
┌─────────────────────────────────────────────┐
│  @Service (UserService)                     │
│  • Business logic                           │
│  • Data processing                          │
│  • Logs business events                     │
└──────────────┬──────────────────────────────┘
               ↓
┌─────────────────────────────────────────────┐
│  RESPONSE (JSON)                            │
│  Returns: {"id":123, "name":"John"}         │
└─────────────────────────────────────────────┘

All logs → application.log → Logstash → Elasticsearch → Kibana
```

### 1. Create Model Class

**User.java:**
```java
package com.example.elkdemo.model;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@NoArgsConstructor
@AllArgsConstructor
public class User {
    private Long id;
    private String name;
    private String email;
    private String role;
    
    // Lombok annotations generate:
    // - Getters and Setters
    // - toString()
    // - equals() and hashCode()
    // - Constructor with all fields
    // - No-argument constructor
}
```

### 2. Create Service Class

**UserService.java:**
```java
package com.example.elkdemo.service;

import com.example.elkdemo.model.User;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Service;

import java.util.ArrayList;
import java.util.List;
import java.util.Optional;

@Service
public class UserService {
    
    // SLF4J Logger for logging
    private static final Logger logger = LoggerFactory.getLogger(UserService.class);
    
    // In-memory user storage (simulating database)
    private List<User> users = new ArrayList<>();
    
    public UserService() {
        // Initialize with sample data
        users.add(new User(1L, "John Doe", "john@example.com", "ADMIN"));
        users.add(new User(2L, "Jane Smith", "jane@example.com", "USER"));
        users.add(new User(3L, "Bob Johnson", "bob@example.com", "USER"));
        
        logger.info("UserService initialized with {} users", users.size());
    }
    
    /**
     * Get all users
     */
    public List<User> getAllUsers() {
        logger.info("Fetching all users. Total count: {}", users.size());
        return users;
    }
    
    /**
     * Get user by ID
     */
    public Optional<User> getUserById(Long id) {
        logger.debug("Searching for user with ID: {}", id);
        
        Optional<User> user = users.stream()
                .filter(u -> u.getId().equals(id))
                .findFirst();
        
        if (user.isPresent()) {
            logger.info("User found: {}", user.get().getName());
        } else {
            logger.warn("User not found with ID: {}", id);
        }
        
        return user;
    }
    
    /**
     * Create new user
     */
    public User createUser(User user) {
        logger.info("Creating new user: {}", user.getName());
        
        // Generate new ID
        Long newId = users.stream()
                .mapToLong(User::getId)
                .max()
                .orElse(0L) + 1;
        
        user.setId(newId);
        users.add(user);
        
        logger.info("User created successfully with ID: {}", newId);
        return user;
    }
    
    /**
     * Update existing user
     */
    public Optional<User> updateUser(Long id, User updatedUser) {
        logger.info("Attempting to update user with ID: {}", id);
        
        for (int i = 0; i < users.size(); i++) {
            if (users.get(i).getId().equals(id)) {
                updatedUser.setId(id);
                users.set(i, updatedUser);
                logger.info("User updated successfully: {}", updatedUser.getName());
                return Optional.of(updatedUser);
            }
        }
        
        logger.error("Failed to update user. User not found with ID: {}", id);
        return Optional.empty();
    }
    
    /**
     * Delete user
     */
    public boolean deleteUser(Long id) {
        logger.info("Attempting to delete user with ID: {}", id);
        
        boolean removed = users.removeIf(u -> u.getId().equals(id));
        
        if (removed) {
            logger.info("User deleted successfully with ID: {}", id);
        } else {
            logger.error("Failed to delete user. User not found with ID: {}", id);
        }
        
        return removed;
    }
    
    /**
     * Simulate an error scenario for testing
     */
    public void simulateError() {
        logger.error("SIMULATED ERROR: This is a test error for ELK monitoring");
        throw new RuntimeException("Simulated exception for testing ELK Stack");
    }
}
```

### 3. Create REST Controller

**UserController.java:**
```java
package com.example.elkdemo.controller;

import com.example.elkdemo.model.User;
import com.example.elkdemo.service.UserService;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;

import java.util.List;

@RestController
@RequestMapping("/api/users")
public class UserController {
    
    private static final Logger logger = LoggerFactory.getLogger(UserController.class);
    
    @Autowired
    private UserService userService;
    
    /**
     * GET /api/users
     * Retrieve all users
     */
    @GetMapping
    public ResponseEntity<List<User>> getAllUsers() {
        logger.info("REST API called: GET /api/users");
        
        try {
            List<User> users = userService.getAllUsers();
            logger.info("Successfully retrieved {} users", users.size());
            return ResponseEntity.ok(users);
            
        } catch (Exception e) {
            logger.error("Error retrieving users: {}", e.getMessage(), e);
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build();
        }
    }
    
    /**
     * GET /api/users/{id}
     * Retrieve user by ID
     */
    @GetMapping("/{id}")
    public ResponseEntity<User> getUserById(@PathVariable Long id) {
        logger.info("REST API called: GET /api/users/{}", id);
        
        return userService.getUserById(id)
                .map(user -> {
                    logger.info("User retrieved successfully: {}", user.getName());
                    return ResponseEntity.ok(user);
                })
                .orElseGet(() -> {
                    logger.warn("User not found with ID: {}", id);
                    return ResponseEntity.notFound().build();
                });
    }
    
    /**
     * POST /api/users
     * Create new user
     */
    @PostMapping
    public ResponseEntity<User> createUser(@RequestBody User user) {
        logger.info("REST API called: POST /api/users - Creating user: {}", user.getName());
        
        try {
            User createdUser = userService.createUser(user);
            logger.info("User created successfully with ID: {}", createdUser.getId());
            return ResponseEntity.status(HttpStatus.CREATED).body(createdUser);
            
        } catch (Exception e) {
            logger.error("Error creating user: {}", e.getMessage(), e);
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build();
        }
    }
    
    /**
     * PUT /api/users/{id}
     * Update existing user
     */
    @PutMapping("/{id}")
    public ResponseEntity<User> updateUser(@PathVariable Long id, @RequestBody User user) {
        logger.info("REST API called: PUT /api/users/{} - Updating user", id);
        
        return userService.updateUser(id, user)
                .map(updatedUser -> {
                    logger.info("User updated successfully: {}", updatedUser.getName());
                    return ResponseEntity.ok(updatedUser);
                })
                .orElseGet(() -> {
                    logger.warn("Update failed. User not found with ID: {}", id);
                    return ResponseEntity.notFound().build();
                });
    }
    
    /**
     * DELETE /api/users/{id}
     * Delete user
     */
    @DeleteMapping("/{id}")
    public ResponseEntity<Void> deleteUser(@PathVariable Long id) {
        logger.info("REST API called: DELETE /api/users/{}", id);
        
        boolean deleted = userService.deleteUser(id);
        
        if (deleted) {
            logger.info("User deleted successfully with ID: {}", id);
            return ResponseEntity.noContent().build();
        } else {
            logger.warn("Delete failed. User not found with ID: {}", id);
            return ResponseEntity.notFound().build();
        }
    }
    
    /**
     * GET /api/users/test/error
     * Simulate error for testing ELK
     */
    @GetMapping("/test/error")
    public ResponseEntity<String> simulateError() {
        logger.info("REST API called: GET /api/users/test/error - Simulating error");
        
        try {
            userService.simulateError();
            return ResponseEntity.ok("This should not be reached");
            
        } catch (Exception e) {
            logger.error("Caught simulated exception: {}", e.getMessage());
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR)
                    .body("Error simulated for ELK testing");
        }
    }
    
    /**
     * GET /api/users/health
     * Health check endpoint
     */
    @GetMapping("/health")
    public ResponseEntity<String> healthCheck() {
        logger.debug("Health check endpoint called");
        return ResponseEntity.ok("Service is healthy");
    }
}
```

### Understanding Logging Levels
```
Logging Levels (Most to Least Verbose):
┌─────────────────────────────────────────────┐
│  TRACE                                      │
│  • Most detailed                            │
│  • Use: Following code execution path       │
│  • Example: "Entering method calculate()"   │
├─────────────────────────────────────────────┤
│  DEBUG                                      │
│  • Detailed diagnostic info                 │
│  • Use: Development troubleshooting         │
│  • Example: "Query returned 5 results"      │
├─────────────────────────────────────────────┤
│  INFO  ← Default in Production              │
│  • General informational messages           │
│  • Use: Normal app flow                     │
│  • Example: "User logged in successfully"   │
├─────────────────────────────────────────────┤
│  WARN                                       │
│  • Potentially harmful situations           │
│  • Use: Recoverable errors                  │
│  • Example: "API rate limit approaching"    │
├─────────────────────────────────────────────┤
│  ERROR                                      │
│  • Error events                             │
│  • Use: Failures that need attention        │
│  • Example: "Database connection failed"    │
├─────────────────────────────────────────────┤
│  FATAL (Not in SLF4J, use ERROR)            │
│  • Very severe errors                       │
│  • Use: App cannot continue                 │
│  • Example: "Out of memory"                 │
└─────────────────────────────────────────────┘

Configuration:
logging.level.root=INFO     ← Shows INFO, WARN, ERROR
logging.level.root=DEBUG    ← Shows DEBUG, INFO, WARN, ERROR
logging.level.root=WARN     ← Shows only WARN, ERROR
```

---

## Step#3: Update application.properties

### Complete Configuration

**application.properties:**
```properties
# ========================================
# Application Configuration
# ========================================
spring.application.name=elk-demo-service
server.port=8080

# ========================================
# Logging Configuration
# ========================================

# Root logging level (applies to all packages)
logging.level.root=INFO

# Package-specific logging levels
logging.level.com.example.elkdemo=DEBUG
logging.level.org.springframework.web=INFO
logging.level.org.springframework.boot=INFO

# Log file configuration
logging.file.name=logs/application.log
logging.file.path=logs

# Log file rotation
logging.logback.rollingpolicy.max-file-size=10MB
logging.logback.rollingpolicy.max-history=30
logging.logback.rollingpolicy.total-size-cap=1GB

# Log pattern for console
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} - %highlight(%-5level) - [%thread] - %logger{36} - %msg%n

# Log pattern for file (will be overridden by logback-spring.xml)
logging.pattern.file=%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n

# ========================================
# Spring Boot Actuator Configuration
# ========================================
management.endpoints.web.exposure.include=health,info,metrics,loggers
management.endpoint.health.show-details=always

# ========================================
# Custom Properties for ELK
# ========================================
elk.environment=development
elk.service.name=${spring.application.name}
elk.service.version=1.0.0
```

### Advanced: Custom Logback Configuration

**Create logback-spring.xml in src/main/resources:**
```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    
    <!-- Import Spring Boot's default configuration -->
    <include resource="org/springframework/boot/logging/logback/defaults.xml"/>
    
    <!-- Properties -->
    <property name="LOG_FILE" value="${LOG_FILE:-${LOG_PATH:-${LOG_TEMP:-${java.io.tmpdir:-/tmp}}/}spring.log}"/>
    <property name="LOG_PATH" value="logs"/>
    <property name="APP_NAME" value="elk-demo-service"/>
    
    <!-- Console Appender with Color -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>
                %clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}
            </pattern>
        </encoder>
    </appender>
    
    <!-- File Appender with JSON Format (for Logstash) -->
    <appender name="FILE_JSON" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_PATH}/application.log</file>
        
        <!-- Rolling Policy -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${LOG_PATH}/application-%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>10MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <maxHistory>30</maxHistory>
            <totalSizeCap>1GB</totalSizeCap>
        </rollingPolicy>
        
        <!-- JSON Encoder for Logstash -->
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <!-- Add custom fields -->
            <customFields>{"app_name":"${APP_NAME}","environment":"development"}</customFields>
            
            <!-- Include caller data (class, method, line number) -->
            <includeCallerData>true</includeCallerData>
            
            <!-- Include MDC (Mapped Diagnostic Context) -->
            <includeMdc>true</includeMdc>
            
            <!-- Include context name -->
            <includeContext>true</includeContext>
            
            <!-- Stack trace configuration -->
            <throwableConverter class="net.logstash.logback.stacktrace.ShortenedThrowableConverter">
                <maxDepthPerThrowable>30</maxDepthPerThrowable>
                <maxLength>2048</maxLength>
                <shortenedClassNameLength>20</shortenedClassNameLength>
                <exclude>sun\.reflect\..*</exclude>
                <exclude>net\.sf\.cglib\..*</exclude>
                <evaluator class="ch.qos.logback.classic.boo
```

```
<!-- Async Appender for better performance -->
<appender name="ASYNC_FILE" class="ch.qos.logback.classic.AsyncAppender">
    <queueSize>512</queueSize>
    <discardingThreshold>0</discardingThreshold>
    <appender-ref ref="FILE_JSON"/>
</appender>

<!-- Root Logger -->
<root level="INFO">
    <appender-ref ref="CONSOLE"/>
    <appender-ref ref="ASYNC_FILE"/>
</root>

<!-- Package-specific loggers -->
<logger name="com.example.elkdemo" level="DEBUG" additivity="false">
    <appender-ref ref="CONSOLE"/>
    <appender-ref ref="ASYNC_FILE"/>
</logger>

<logger name="org.springframework.web" level="INFO"/>
<logger name="org.springframework.boot" level="INFO"/>
```

</configuration> 

### Understanding JSON Log Format

**Traditional Log Format:**

```
2025-11-01 14:35:21 INFO  [http-nio-8080-exec-1] c.e.elkdemo.controller.UserController : REST API called: GET /api/users
```

**JSON Log Format (Logstash-friendly):**

json

```json
{
  "@timestamp": "2025-11-01T14:35:21.123+00:00",
  "@version": "1",
  "message": "REST API called: GET /api/users",
  "logger_name": "com.example.elkdemo.controller.UserController",
  "thread_name": "http-nio-8080-exec-1",
  "level": "INFO",
  "level_value": 20000,
  "app_name": "elk-demo-service",
  "environment": "development",
  "caller": {
    "class_name": "com.example.elkdemo.controller.UserController",
    "method_name": "getAllUsers",
    "file_name": "UserController.java",
    "line_number": 35
  },
  "stack_trace": null
}
```

**Why JSON?**

```
Advantages of JSON Logs:
├─ Easy to parse (no complex regex needed)
├─ Structured data (fields are already separated)
├─ Faster processing in Logstash
├─ Consistent format across services
└─ Better for machine analysis

Disadvantage:
└─ Less human-readable in console
   (That's why we use colored console + JSON file)
```

----------

## Step#4: Create logstash.conf file

### Understanding the Configuration

**Location Options:**

```
Option 1: In Logstash installation directory
/path/to/logstash-8.11.0/config/logstash.conf

Option 2: Custom location
/etc/logstash/conf.d/spring-boot.conf

Option 3: Project directory (for easy version control)
elk-demo/logstash/logstash.conf
```

### Complete Logstash Configuration

**logstash.conf:**

ruby

```ruby
# ========================================
# INPUT SECTION
# Define where logs come from
# ========================================

input {
  # Read from log file
  file {
    # Path to your Spring Boot log file
    # Use absolute path for production
    path => "/path/to/elk-demo/logs/application.log"
    
    # Start reading from beginning of file (for testing)
    # Use "end" in production to only read new logs
    start_position => "beginning"
    
    # Sincedb tracks what has been read
    # Set to /dev/null for testing (re-reads entire file each time)
    # Use default location in production
    sincedb_path => "/dev/null"
    
    # Codec for JSON logs
    codec => "json"
    
    # Type identifier (helps in filtering)
    type => "spring-boot-log"
    
    # Tags for identification
    tags => ["spring-boot", "elk-demo"]
  }
}

# ========================================
# FILTER SECTION
# Process and enrich log data
# ========================================

filter {
  # Only process spring-boot-log types
  if [type] == "spring-boot-log" {
    
    # Parse timestamp if not already in @timestamp
    if [timestamp] {
      date {
        match => ["timestamp", "ISO8601"]
        target => "@timestamp"
      }
    }
    
    # Add hostname
    mutate {
      add_field => {
        "hostname" => "%{host}"
      }
    }
    
    # Parse log level and set severity
    if [level] {
      mutate {
        uppercase => ["level"]
      }
      
      # Add numeric severity for sorting
      if [level] == "TRACE" {
        mutate { add_field => { "severity" => 1 } }
      } else if [level] == "DEBUG" {
        mutate { add_field => { "severity" => 2 } }
      } else if [level] == "INFO" {
        mutate { add_field => { "severity" => 3 } }
      } else if [level] == "WARN" {
        mutate { add_field => { "severity" => 4 } }
      } else if [level] == "ERROR" {
        mutate { add_field => { "severity" => 5 } }
      }
    }
    
    # Extract class name from logger_name
    if [logger_name] {
      grok {
        match => {
          "logger_name" => "(?<package_name>.*?)\.(?<class_name>[^.]+)$"
        }
      }
    }
    
    # Parse HTTP request information from message
    if [message] =~ /REST API called:/ {
      grok {
        match => {
          "message" => "REST API called: %{WORD:http_method} %{URIPATHPARAM:http_path}"
        }
      }
      mutate {
        add_tag => ["api_call"]
      }
    }
    
    # Detect errors
    if [level] == "ERROR" or [stack_trace] {
      mutate {
        add_tag => ["error"]
      }
    }
    
    # Detect specific events
    if [message] =~ /User created/ {
      mutate {
        add_tag => ["user_created"]
        add_field => { "event_type" => "user_creation" }
      }
    }
    
    if [message] =~ /User deleted/ {
      mutate {
        add_tag => ["user_deleted"]
        add_field => { "event_type" => "user_deletion" }
      }
    }
    
    # Extract user ID from messages
    if [message] =~ /ID: / {
      grok {
        match => {
          "message" => "ID: %{NUMBER:user_id}"
        }
      }
    }
    
    # Remove unnecessary fields to reduce storage
    mutate {
      remove_field => ["host", "path"]
    }
  }
}

# ========================================
# OUTPUT SECTION
# Send processed logs to destinations
# ========================================

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["localhost:9200"]
    
    # Index pattern with date
    # Creates indices like: spring-boot-logs-2025.11.01
    index => "spring-boot-logs-%{+YYYY.MM.dd}"
    
    # Document ID (optional, auto-generated if not specified)
    # document_id => "%{[@metadata][_id]}"
  }
  
  # Also output to console for debugging (comment out in production)
  stdout {
    codec => rubydebug
  }
}
```

### Advanced Logstash Configuration Examples

**1. Multi-Service Configuration:**

ruby

```ruby
input {
  file {
    path => "/var/log/user-service/application.log"
    codec => "json"
    type => "user-service"
    tags => ["microservice", "user-service"]
  }
  
  file {
    path => "/var/log/product-service/application.log"
    codec => "json"
    type => "product-service"
    tags => ["microservice", "product-service"]
  }
  
  file {
    path => "/var/log/order-service/application.log"
    codec => "json"
    type => "order-service"
    tags => ["microservice", "order-service"]
  }
}

filter {
  # Add service name field
  mutate {
    add_field => {
      "service_name" => "%{type}"
    }
  }
  
  # Common filtering for all services
  # ... (add common filters here)
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    # Different index per service
    index => "%{service_name}-%{+YYYY.MM.dd}"
  }
}
```

**2. Configuration with Conditional Routing:**

ruby

```ruby
output {
  # Send errors to separate index
  if "error" in [tags] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "spring-boot-errors-%{+YYYY.MM.dd}"
    }
  }
  
  # Send API calls to separate index
  if "api_call" in [tags] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "spring-boot-api-%{+YYYY.MM.dd}"
    }
  }
  
  # Send everything to main index
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "spring-boot-logs-%{+YYYY.MM.dd}"
  }
}
```

**3. Production-Ready Configuration:**

ruby

```ruby
input {
  file {
    path => "/var/log/spring-boot/application.log"
    start_position => "end"  # Only read new logs
    codec => "json"
    type => "spring-boot-log"
    
    # Use default sincedb location
    # sincedb_path => "/var/lib/logstash/sincedb"
  }
}

filter {
  # Remove PII (Personally Identifiable Information)
  if [email] {
    mutate {
      gsub => [
        "email", "@.*", "@***REDACTED***"
      ]
    }
  }
  
  # Rate limiting - drop excessive DEBUG logs
  if [level] == "DEBUG" {
    throttle {
      before_count => 100
      after_count => 10
      period => 60
      key => "%{logger_name}"
      add_tag => "throttled"
    }
    
    if "throttled" in [tags] {
      drop { }
    }
  }
}

output {
  elasticsearch {
    hosts => ["es-node1:9200", "es-node2:9200", "es-node3:9200"]
    index => "spring-boot-logs-%{+YYYY.MM.dd}"
    
    # Authentication
    user => "logstash_user"
    password => "${LOGSTASH_PASSWORD}"
    
    # Performance tuning
    workers => 2
    flush_size => 500
    idle_flush_time => 5
  }
}
```

### Memory Visualization: Logstash Pipeline Flow

```
┌─────────────────────────────────────────────────────┐
│  Raw Log Entry in File:                             │
│  {"@timestamp":"2025-11-01T14:35:21.123Z",          │
│   "level":"ERROR","message":"User not found"}       │
└────────────────────┬────────────────────────────────┘
                     ↓
         ┌───────────────────────┐
         │   INPUT (File)        │
         │   • Reads the file    │
         │   • Parses JSON       │
         │   • Creates event     │
         └──────────┬────────────┘
                    ↓
         ┌───────────────────────┐
         │   FILTER #1 (Date)    │
         │   • Parses timestamp  │
         │   • Sets @timestamp   │
         └──────────┬────────────┘
                    ↓
         ┌───────────────────────┐
         │   FILTER #2 (Mutate)  │
         │   • Adds hostname     │
         │   • Adds severity     │
         └──────────┬────────────┘
                    ↓
         ┌───────────────────────┐
         │   FILTER #3 (Grok)    │
         │   • Extracts patterns │
         │   • Parses user_id    │
         └──────────┬────────────┘
                    ↓
         ┌───────────────────────┐
         │   FILTER #4 (Mutate)  │
         │   • Adds tags         │
         │   • Removes fields    │
         └──────────┬────────────┘
                    ↓
         ┌───────────────────────┐
         │   OUTPUT (ES)         │
         │   • Sends to ES       │
         │   • Index created     │
         └───────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────┐
│  Enriched Document in Elasticsearch:                │
│  {                                                  │
│    "@timestamp": "2025-11-01T14:35:21.123Z",        │
│    "level": "ERROR",                                │
│    "severity": 5,                                   │
│    "message": "User not found",                     │
│    "user_id": "123",                                │
│    "hostname": "server-1",                          │
│    "class_name": "UserService",                     │
│    "tags": ["error", "spring-boot"],                │
│    "service_name": "elk-demo-service"               │
│  }                                                  │
└─────────────────────────────────────────────────────┘
```

----------

## Step#5: Run your application & ELK Stack

### Pre-Flight Checklist

```
Before Running:
✓ Java installed and JAVA_HOME set
✓ Elasticsearch installed and configured
✓ Kibana installed and configured
✓ Logstash installed and configured
✓ Spring Boot application built
✓ logstash.conf file created
✓ Log directory exists: elk-demo/logs/
```

### Startup Sequence

**The correct order is important:**

```
Startup Order:
1. Elasticsearch (must start first)
   ↓ Wait for cluster to be ready
2. Kibana (connects to Elasticsearch)
   ↓ Wait for Kibana to be ready
3. Spring Boot Application (generates logs)
   ↓ Logs written to file
4. Logstash (reads logs, sends to ES)
```

### Step-by-Step Startup Guide

**Terminal 1: Start Elasticsearch**

bash

```bash
# Navigate to Elasticsearch directory
cd /path/to/elasticsearch-8.11.0/

# Start Elasticsearch
./bin/elasticsearch

# Wait for this message:
# "started" - cluster status: green

# Verify (in new terminal):
curl -X GET "localhost:9200/_cluster/health?pretty"

# Expected: "status" : "green"
```

**Terminal 2: Start Kibana**

bash

```bash
# Navigate to Kibana directory
cd /path/to/kibana-8.11.0/

# Start Kibana
./bin/kibana

# Wait for this message:
# "http server running at http://localhost:5601"

# Verify in browser:
# http://localhost:5601
```

**Terminal 3: Start Spring Boot Application**

bash

```bash
# Navigate to project directory
cd /path/to/elk-demo/

# Option 1: Using Maven
./mvnw spring-boot:run

# Option 2: Using IDE
# Right-click on ElkDemoApplication.java → Run As → Spring Boot App

# Option 3: Using JAR (after building)
./mvnw clean package
java -jar target/elk-demo-0.0.1-SNAPSHOT.jar

# Wait for:
# "Started ElkDemoApplication in X seconds"

# Verify:
curl http://localhost:8080/api/users/health
# Expected: "Service is healthy"
```

**Terminal 4: Start Logstash**

bash

```bash
# Navigate to Logstash directory
cd /path/to/logstash-8.11.0/

# Update logstash.conf with correct log file path
# Edit: config/logstash.conf
# Change: path => "/full/path/to/elk-demo/logs/application.log"

# Test configuration
./bin/logstash -f config/logstash.conf --config.test_and_exit

# If test passes, start Logstash
./bin/logstash -f config/logstash.conf

# Wait for:
# "Pipelines running" message

# You should see log entries being processed in console
```

### Generating Test Data

**Open Terminal 5 for API Testing:**

bash

```bash
# Test 1: Get all users
curl -X GET http://localhost:8080/api/users

# Test 2: Get specific user
curl -X GET http://localhost:8080/api/users/1

# Test 3: Get non-existent user (generates WARN log)
curl -X GET http://localhost:8080/api/users/999

# Test 4: Create new user
curl -X POST http://localhost:8080/api/users \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Alice Johnson",
    "email": "alice@example.com",
    "role": "USER"
  }'

# Test 5: Update user
curl -X PUT http://localhost:8080/api/users/1 \
  -H "Content-Type: application/json" \
  -d '{
    "name": "John Updated",
    "email": "john.updated@example.com",
    "role": "ADMIN"
  }'

# Test 6: Delete user
curl -X DELETE http://localhost:8080/api/users/3

# Test 7: Simulate error (generates ERROR log)
curl -X GET http://localhost:8080/api/users/test/error

# Test 8: Generate load (100 requests)
for i in {1..100}; do
  curl -s http://localhost:8080/api/users > /dev/null
  echo "Request $i completed"
done
```

### Verification Steps

**1. Check Log File:**

bash

```bash
# View the log file
tail -f /path/to/elk-demo/logs/application.log

# You should see JSON formatted logs:
{"@timestamp":"2025-11-01T14:35:21.123Z","level":"INFO",...}
```

**2. Check Logstash Processing:**

bash

```bash
# In Terminal 4 (Logstash), you should see:
{
    "@timestamp" => 2025-11-01T14:35:21.123Z,
         "level" => "INFO",
       "message" => "REST API called: GET /api/users",
    "logger_name" => "com.example.elkdemo.controller.UserController",
    ...
}
```

**3. Check Elasticsearch Indices:**

bash

```bash
# List all indices
curl -X GET "localhost:9200/_cat/indices?v"

# Expected output:
# health status index                    docs.count
# green  open   spring-boot-logs-2025.11.01    245

# Query the index
curl -X GET "localhost:9200/spring-boot-logs-2025.11.01/_search?pretty" \
  -H 'Content-Type: application/json' \
  -d '{
    "query": {
      "match_all": {}
    },
    "size": 1
  }'
```

### Troubleshooting Common Issues

**Issue 1: Logs not appearing in Elasticsearch**

bash

```bash
# Check 1: Is the log file being created?
ls -lh /path/to/elk-demo/logs/
# Should see: application.log

# Check 2: Is Logstash reading the file?
# Look for this in Logstash output:
# "pipeline started" and file watch messages

# Check 3: Is file path correct in logstash.conf?
grep "path =>" /path/to/logstash-8.11.0/config/logstash.conf

# Fix: Update path to absolute path
# path => "/full/absolute/path/to/elk-demo/logs/application.log"
```

**Issue 2: Logstash not starting**

bash

```bash
# Check Java version
java -version
# Need Java 11 or higher

# Check configuration syntax
./bin/logstash -f config/logstash.conf --config.test_and_exit

# Check for port conflicts
netstat -tulpn | grep 9600
# Logstash uses port 9600 for monitoring
```

**Issue 3: Elasticsearch not accepting data**

bash

```bash
# Check Elasticsearch health
curl -X GET "localhost:9200/_cluster/health?pretty"

# Check disk space
df -h
# Elasticsearch stops accepting data if disk is >90% full

# Check Elasticsearch logs
tail -f /path/to/elasticsearch-8.11.0/logs/my-elk-cluster.log
```

**Issue 4: Spring Boot logs not in JSON format**

bash

```bash
# Check if logstash-logback-encoder is in pom.xml
grep "logstash-logback-encoder" pom.xml

# Check if logback-spring.xml exists
ls -l src/main/resources/logback-spring.xml

# Rebuild application
./mvnw clean package
```

### System Resource Monitoring

**Monitor Resources:**

bash

```bash
# Check memory usage
free -h

# Check CPU usage
top

# Recommended resources:
# Elasticsearch: 2-4GB RAM
# Kibana: 1GB RAM
# Logstash: 1-2GB RAM
# Spring Boot: 512MB-1GB RAM
# Total: 5-8GB RAM recommended
```

----------

## How to Test in Kibana Dashboard?

### Initial Kibana Setup

**Step 1: Access Kibana**

```
1. Open browser
2. Navigate to: http://localhost:5601
3. You should see Kibana home page
```

**Step 2: Create Index Pattern**

```
Index Pattern Setup:
┌──────────────────────────────────────────┐
│  What is an Index Pattern?               │
│                                          │
│  It's like a "database view" that tells │
│  Kibana which indices to search          │
│                                          │
│  Example:                                │
│  Pattern: spring-boot-logs-*             │
│  Matches:                                │
│    ✓ spring-boot-logs-2025.11.01         │
│    ✓ spring-boot-logs-2025.11.02         │
│    ✓ spring-boot-logs-2025.11.03         │
└──────────────────────────────────────────┘
```

**Creating Index Pattern - Step by Step:**

```
Step 1: Click on "Management" (gear icon) in left sidebar
        ↓
Step 2: Click "Stack Management"
        ↓
Step 3: Under "Kibana" section, click "Index Patterns"
        ↓
Step 4: Click "Create index pattern"
        ↓
Step 5: Enter index pattern name:
        Name: spring-boot-logs-*
        [This matches all daily indices]
        ↓
Step 6: Click "Next step"
        ↓
Step 7: Select time field:
        Time field: @timestamp
        [This is crucial for time-based analysis]
        ↓
Step 8: Click "Create index pattern"
        ↓
        ✓ Index pattern created!
```

**Verification:**

bash

```bash
# Check if indices exist in Elasticsearch
curl -X GET "localhost:9200/_cat/indices?v" | grep spring-boot

# Check document count
curl -X GET "localhost:9200/spring-boot-logs-*/_count?pretty"
```

### Exploring the Discover Tab

**Navigate to Discover:**

```
1. Click on "Discover" in left sidebar (compass icon)
2. Select your index pattern: "spring-boot-logs-*"
3. You should see your logs!
```

**Understanding the Discover Interface:**

```
┌────────────────────────────────────────────────────────────┐
│  KIBANA DISCOVER INTERFACE                                 │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  [Time Picker]  Last 15 minutes ▼  [Refresh] [Save]       │
│                                                            │
├────────────────────────────────────────────────────────────┤
│  Search Bar:  level:"ERROR"                         [Search]│
├─────────┬──────────────────────────────────────────────────┤
│ FIELDS  │  DOCUMENTS                                       │
│         │                                                  │
│ Selected│  ┌─────────────────────────────────────────────┐│
│ ✓ @times│  │ Nov 1, 2025 @ 14:35:21.123                  ││
│ ✓ level │  │ level: ERROR                                 ││
│ ✓ message│  │ message: User not found with ID: 999        ││
│         │  │ logger_name: c.e.elkdemo.controller...      ││
│ Available│  │ [View details] [View context]               ││
│ • class_│  └─────────────────────────────────────────────┘│
│ • thread│  ┌─────────────────────────────────────────────┐│
│ • host  │  │ Nov 1, 2025 @ 14:35:20.456                  ││
│ • app_na│  │ level: INFO                                  ││
│ ...     │  │ message: REST API called: GET /api/users    ││
│         │  └─────────────────────────────────────────────┘│
│         │                                                  │
├─────────┴──────────────────────────────────────────────────┤
│  [Histogram showing log distribution over time]            │
│   █                                                         │
│   █  █                                                      │
│   █  █  █                                                   │
│   █  █  █  █                                                │
│  14:30  14:35  14:40  14:45                                 │
└────────────────────────────────────────────────────────────┘
```

### Adding Fields to View

**Select useful fields to display:**

```
1. In the FIELDS section (left sidebar), hover over a field name
2. Click the "+" button to add it to the table
3. Recommended fields to add:
   ✓ @timestamp
   ✓ level
   ✓ message
   ✓ logger_name
   ✓ class_name
   ✓ thread_name
   ✓ http_method (if available)
   ✓ http_path (if available)
   ✓ user_id (if available)
```

### Filtering Data

**Using the Filter Bar:**

```
Method 1: Click on field values in documents
├─ Click on "ERROR" in level field
├─ Options appear:
│  ├─ Filter for value (shows only ERROR logs)
│  └─ Filter out value (hides ERROR logs)

Method 2: Use search bar (covered in next section)

Method 3: Add manual filters
├─ Click "+ Add filter"
├─ Select field: level
├─ Select operator: is
├─ Enter value: ERROR
└─ Click "Save"
```

### Time Range Selection

**Adjusting Time Range:**

```
Common Time Ranges:
├─ Last 15 minutes (default)
├─ Last 1 hour
├─ Last 24 hours
├─ Last 7 days
├─ Today
├─ This week
└─ Custom (specify exact start and end)

Quick Time Picker:
┌──────────────────────────────┐
│  Commonly used               │
│  • Today                     │
│  • Last 7 days               │
│  • Last 30 days              │
│                              │
│  Recently used               │
│  • Last 15 minutes           │
│  • Last 1 hour               │
│                              │
│  Quick select                │
│  • s = seconds               │
│  • m = minutes               │
│  • h = hours                 │
│  • d = days                  │
│  • w = weeks                 │
│  • M = months                │
│  • y = years                 │
│                              │
│  Example: Last 2h            │
│  [Apply]                     │
└──────────────────────────────┘
```

----------

## How to Search Data in Kibana Dashboard?

### Search Capabilities Overview

```
Kibana offers TWO query languages:
┌──────────────────────────────────────────┐
│  KQL (Kibana Query Language)             │
│  • Default in newer Kibana versions      │
│  • Simpler, more user-friendly           │
│  • Less powerful than Lucene             │
│  • Recommended for beginners             │
└──────────────────────────────────────────┘
┌──────────────────────────────────────────┐
│  Lucene                                  │
│  • Classic Elasticsearch query syntax    │
│  • More powerful and flexible            │
│  • Supports complex queries              │
│  • Preferred by advanced users           │
└──────────────────────────────────────────┘
```

----------

## How to Switch Between KQL and Lucene Syntax in Kibana?

**Switching Query Language:**

```
Step-by-Step:
1. Go to Discover tab
2. Look at the search bar
3. On the right side of search bar, you'll see:
   [KQL ▼]  or  [Lucene ▼]
4. Click on it
5. Select your preferred language
6. A blue banner appears: "Language changed to Lucene"
```

**Visual Indicator:**

```
┌────────────────────────────────────────────────┐
│  Search: level:"ERROR"            [KQL ▼]      │
│                                                 │
│  Click dropdown to switch ───────────┘         │
│                                                 │
│  Options:                                       │
│  • KQL (Kibana Query Language)                 │
│  • Lucene                                      │
└────────────────────────────────────────────────┘
```

----------

## Search By Field (Lucene)

### Basic Field Search Syntax

```
Syntax: fieldname:value

Examples:
┌───────────────────────────────────────────┐
│  Search by log level:                     │
│  level:ERROR                              │
│  level:INFO                               │
│  level:WARN                               │
├───────────────────────────────────────────┤
│  Search by class name:                    │
│  class_name:UserController                │
│  logger_name:UserService                  │
├───────────────────────────────────────────┤
│  Search by HTTP method:                   │
│  http_method:GET                          │
│  http_method:POST                         │
├───────────────────────────────────────────┤
│  Search by service name:                  │
│  app_name:"elk-demo-service"              │
│  service_name:"user-service"              │
└───────────────────────────────────────────┘
```

### Real-World Examples

**Example 1: Find all ERROR logs:**

```
level:ERROR
```

**Example 2: Find logs from specific class:**

```
class_name:UserController
```

**Example 3: Find all GET requests:**

```
http_method:GET
```

**Example 4: Find logs




with specific user ID:**

```
user_id:123
```

**Example 5: Find logs from specific thread:**
```
thread_name:"http-nio-8080-exec-1"
```

### Field Search with Exact Phrases
```
Use quotes for exact phrase matching:

With quotes (exact match):
message:"User not found"
└─ Matches only: "User not found"

Without quotes (any word match):
message:User not found
└─ Matches: "User created", "not available", "found error"
```

---

## Free Text (Lucene)

### Basic Free Text Search
```
Syntax: Simply type the text (no field name)

How it works:
├─ Searches across ALL fields
├─ Case-insensitive by default
└─ Matches partial words

Examples:
┌────────────────────────────────────────┐
│  Search for "error" anywhere:          │
│  error                                 │
│  Matches:                              │
│    • level: "ERROR"                    │
│    • message: "Database error"         │
│    • stack_trace: "NullPointerError"   │
├────────────────────────────────────────┤
│  Search for user-related logs:         │
│  user                                  │
│  Matches:                              │
│    • "User created"                    │
│    • "user-service"                    │
│    • "username: john"                  │
├────────────────────────────────────────┤
│  Search for specific email:            │
│  john@example.com                      │
│  Matches any log containing this email │
└────────────────────────────────────────┘
```

### Free Text with Quotes
```
Exact phrase search:

"User not found"
└─ Matches only the exact phrase

Multiple words without quotes:
User not found
└─ Matches logs containing ANY of these words:
   • "User created"
   • "not available"
   • "Item found"
```

### Real-World Examples

**Example 1: Find all authentication-related logs:**
```
authentication
OR
login
OR
"sign in"
```

**Example 2: Find database-related issues:**
```
database
OR
"connection timeout"
OR
"query failed"
```

**Example 3: Find payment processing logs:**
```
payment OR transaction OR invoice
```

---

## Boolean Operators (Lucene): AND, OR, NOT

### Understanding Boolean Logic

**Memory Visualization:**
```
Venn Diagram Analogy:
┌─────────────────────────────────────────┐
│  AND (Intersection)                     │
│  ┌──────────┐                           │
│  │   ERROR  │╲                          │
│  │          │ ╲                         │
│  │      ┌───┼──╲──────┐                │
│  │      │   │   ╲     │                │
│  │      │   │BOTH│    │                │
│  │      │   │    │    │                │
│  └──────┼───┘    ╲    │                │
│         │         ╲   │                │
│         │    UserController            │
│         └──────────────┘               │
│  Result: Only logs that are ERROR      │
│          AND from UserController       │
└─────────────────────────────────────────┘

┌─────────────────────────────────────────┐
│  OR (Union)                             │
│  ┌──────────┐                           │
│  │   ERROR  │╲                          │
│  │          │ ╲                         │
│  │      ┌───┼──╲──────┐                │
│  │ ALL  │ ALL│ALL│ ALL│                │
│  │      │   │    │    │                │
│  └──────┼───┘    ╲    │                │
│         │         ╲   │                │
│         │      WARN   │                │
│         └──────────────┘               │
│  Result: Logs that are EITHER          │
│          ERROR OR WARN                 │
└─────────────────────────────────────────┘

┌─────────────────────────────────────────┐
│  NOT (Exclusion)                        │
│  ┌──────────────────────────┐          │
│  │   ALL LOGS               │          │
│  │                          │          │
│  │   ┌──────────┐           │          │
│  │   │  EXCLUDE │           │          │
│  │   │   DEBUG  │           │          │
│  │   └──────────┘           │          │
│  │                          │          │
│  └──────────────────────────┘          │
│  Result: All logs EXCEPT DEBUG         │
└─────────────────────────────────────────┘
```

### AND Operator

**Syntax: Both conditions must be true**
```
field1:value1 AND field2:value2

Examples:
┌───────────────────────────────────────────────┐
│  Example 1: ERROR logs from UserController    │
│  level:ERROR AND class_name:UserController    │
│                                               │
│  Result: Only logs matching BOTH conditions   │
│    ✓ level=ERROR, class=UserController       │
│    ✗ level=ERROR, class=ProductService       │
│    ✗ level=INFO, class=UserController        │
├───────────────────────────────────────────────┤
│  Example 2: POST requests that failed         │
│  http_method:POST AND level:ERROR             │
│                                               │
│  Result:                                      │
│    ✓ POST request with error                 │
│    ✗ GET request with error                  │
│    ✗ POST request successful                 │
├───────────────────────────────────────────────┤
│  Example 3: Specific user's error logs        │
│  user_id:123 AND level:ERROR                  │
│                                               │
│  Result: Only errors for user 123             │
└───────────────────────────────────────────────┘
```

**Real-World Use Cases:**
```
Use Case 1: Find failed payment transactions
http_path:"/api/payment" AND level:ERROR

Use Case 2: Find slow database queries
message:"database" AND message:"timeout"

Use Case 3: Find specific service errors
service_name:"order-service" AND level:ERROR AND message:"inventory"
```

### OR Operator

**Syntax: At least one condition must be true**
```
field1:value1 OR field2:value2

Examples:
┌───────────────────────────────────────────────┐
│  Example 1: Show all errors and warnings      │
│  level:ERROR OR level:WARN                    │
│                                               │
│  Result: Logs matching EITHER condition       │
│    ✓ level=ERROR                              │
│    ✓ level=WARN                               │
│    ✗ level=INFO                               │
├───────────────────────────────────────────────┤
│  Example 2: Find user creation or deletion    │
│  message:"User created" OR message:"User deleted"│
│                                               │
│  Result:                                      │
│    ✓ "User created successfully"              │
│    ✓ "User deleted from system"               │
│    ✗ "User updated"                           │
├───────────────────────────────────────────────┤
│  Example 3: Multiple HTTP methods             │
│  http_method:POST OR http_method:PUT OR http_method:DELETE│
│                                               │
│  Result: All modification requests            │
└───────────────────────────────────────────────┘
```

**Real-World Use Cases:**
```
Use Case 1: Monitor all critical issues
level:ERROR OR level:FATAL OR message:"critical"

Use Case 2: Track all authentication events
message:"login" OR message:"logout" OR message:"authentication"

Use Case 3: Find all user-related operations
message:"user created" OR message:"user updated" OR message:"user deleted"
```

### NOT Operator

**Syntax: Exclude matching documents**
```
NOT field:value
-field:value  (alternative syntax)

Examples:
┌───────────────────────────────────────────────┐
│  Example 1: All logs except DEBUG             │
│  NOT level:DEBUG                              │
│  OR                                           │
│  -level:DEBUG                                 │
│                                               │
│  Result:                                      │
│    ✓ level=INFO                               │
│    ✓ level=ERROR                              │
│    ✗ level=DEBUG                              │
├───────────────────────────────────────────────┤
│  Example 2: Exclude health check requests    │
│  NOT http_path:"/health"                      │
│                                               │
│  Result: All requests except health checks    │
├───────────────────────────────────────────────┤
│  Example 3: Exclude specific service          │
│  NOT service_name:"monitoring-service"        │
│                                               │
│  Result: Logs from all services except        │
│           monitoring service                  │
└───────────────────────────────────────────────┘
```

**Real-World Use Cases:**
```
Use Case 1: Find issues excluding known noisy logs
level:ERROR NOT message:"known issue"

Use Case 2: Production logs without test data
environment:production NOT user_id:test*

Use Case 3: All requests except GET (modifications only)
NOT http_method:GET
```

### Combining Boolean Operators

**Complex Queries with Parentheses:**
```
Use parentheses to control evaluation order:

Example 1: Errors or warnings from specific service
(level:ERROR OR level:WARN) AND service_name:"user-service"

Breakdown:
├─ (level:ERROR OR level:WARN)  ← Evaluated first
│   └─ Finds all errors and warnings
└─ AND service_name:"user-service"
    └─ Filters to only user-service

Result: Errors and warnings from user-service only

Example 2: Critical issues excluding health checks
(level:ERROR OR level:FATAL) AND NOT http_path:"/health"

Breakdown:
├─ (level:ERROR OR level:FATAL)  ← Critical logs
└─ NOT http_path:"/health"       ← Exclude health
Result: Critical issues, no health checks

Example 3: User operations excluding test users
(message:"user created" OR message:"user deleted") AND NOT user_id:test*

Breakdown:
├─ User creation/deletion events
└─ Excluding test user IDs
Result: Real user operations only
```

### Order of Operations (Precedence)
```
Operator Precedence (highest to lowest):
1. ( ) Parentheses
2. NOT, -
3. AND
4. OR

Examples:

Query: A OR B AND C
Evaluated as: A OR (B AND C)

To change: (A OR B) AND C

Query: NOT A AND B
Evaluated as: (NOT A) AND B

Query: A AND NOT B OR C
Evaluated as: (A AND (NOT B)) OR C

Best Practice: Always use parentheses for clarity!
```

### Real-World Complex Queries

**Scenario 1: Find payment failures from production, excluding test users:**
```
Query:
(level:ERROR AND http_path:"/api/payment") AND environment:production AND NOT user_id:test*

Explanation:
├─ level:ERROR AND http_path:"/api/payment"
│  └─ Payment endpoint errors
├─ environment:production
│  └─ Only production environment
└─ NOT user_id:test*
   └─ Exclude test users

Use Case: Payment monitoring dashboard
```

**Scenario 2: Find all modification operations with errors or warnings:**
```
Query:
(http_method:POST OR http_method:PUT OR http_method:DELETE) AND (level:ERROR OR level:WARN)

Explanation:
├─ (http_method:POST OR PUT OR DELETE)
│  └─ All modification requests
└─ (level:ERROR OR level:WARN)
   └─ Only problematic ones

Use Case: Data integrity monitoring
```

**Scenario 3: Security audit - authentication events excluding successful logins:**
```
Query:
message:"authentication" AND NOT message:"successful"

Explanation:
├─ message:"authentication"
│  └─ All auth events
└─ NOT message:"successful"
   └─ Exclude successful ones
Result: Failed authentication attempts

Use Case: Security incident detection
```

---

## Ranges (Lucene): [ ], { }, :>, :>=, :<, :<=

### Understanding Range Queries

**Range query types:**
```
Inclusive Ranges: [ ]
├─ Includes boundary values
└─ Syntax: field:[min TO max]

Exclusive Ranges: { }
├─ Excludes boundary values
└─ Syntax: field:{min TO max}

Comparison Operators:
├─ :>  Greater than
├─ :>= Greater than or equal
├─ :<  Less than
└─ :<= Less than or equal
```

### Numeric Range Queries

**Using [ ] (Inclusive):**
```
Syntax: field:[min TO max]

Examples:
┌────────────────────────────────────────────┐
│  Example 1: User IDs between 10 and 20     │
│  user_id:[10 TO 20]                        │
│                                            │
│  Matches:                                  │
│    ✓ user_id: 10 (included)               │
│    ✓ user_id: 15                          │
│    ✓ user_id: 20 (included)               │
│    ✗ user_id: 9                           │
│    ✗ user_id: 21                          │
├────────────────────────────────────────────┤
│  Example 2: Severity levels 3 to 5         │
│  severity:[3 TO 5]                         │
│                                            │
│  Matches:                                  │
│    ✓ INFO (3), WARN (4), ERROR (5)        │
│    ✗ DEBUG (2)                            │
├────────────────────────────────────────────┤
│  Example 3: Response codes 200-299         │
│  status_code:[200 TO 299]                  │
│                                            │
│  Matches: All successful HTTP responses    │
└────────────────────────────────────────────┘
```

**Using { } (Exclusive):**
```
Syntax: field:{min TO max}

Examples:
┌────────────────────────────────────────────┐
│  Example 1: User IDs between 10 and 20     │
│  user_id:{10 TO 20}                        │
│                                            │
│  Matches:                                  │
│    ✗ user_id: 10 (excluded)               │
│    ✓ user_id: 15                          │
│    ✗ user_id: 20 (excluded)               │
│    ✗ user_id: 9                           │
│    ✗ user_id: 21                          │
├────────────────────────────────────────────┤
│  Example 2: Values strictly between 0-100  │
│  percentage:{0 TO 100}                     │
│                                            │
│  Matches: 0.1 to 99.9 (not 0 or 100)      │
└────────────────────────────────────────────┘
```

### Comparison Operators

**Greater Than (>):**
```
Syntax: field:>value

Examples:
┌────────────────────────────────────────────┐
│  Example 1: High severity logs only        │
│  severity:>3                               │
│                                            │
│  Matches:                                  │
│    ✓ severity: 4 (WARN)                   │
│    ✓ severity: 5 (ERROR)                  │
│    ✗ severity: 3 (INFO)                   │
├────────────────────────────────────────────┤
│  Example 2: Large file sizes               │
│  file_size:>1000000                        │
│                                            │
│  Matches: Files larger than 1MB            │
└────────────────────────────────────────────┘
```

**Greater Than or Equal (>=):**
```
Syntax: field:>=value

Examples:
┌────────────────────────────────────────────┐
│  Example 1: WARN and ERROR logs            │
│  severity:>=4                              │
│                                            │
│  Matches:                                  │
│    ✓ severity: 4 (WARN)                   │
│    ✓ severity: 5 (ERROR)                  │
│    ✗ severity: 3 (INFO)                   │
├────────────────────────────────────────────┤
│  Example 2: HTTP errors (400+)             │
│  status_code:>=400                         │
│                                            │
│  Matches: 400, 404, 500, etc.              │
└────────────────────────────────────────────┘
```

**Less Than (<):**
```
Syntax: field:<value

Examples:
┌────────────────────────────────────────────┐
│  Example 1: Low severity logs              │
│  severity:<3                               │
│                                            │
│  Matches:                                  │
│    ✓ severity: 1 (TRACE)                  │
│    ✓ severity: 2 (DEBUG)                  │
│    ✗ severity: 3 (INFO)                   │
├────────────────────────────────────────────┤
│  Example 2: Fast responses (<100ms)        │
│  response_time:<100                        │
│                                            │
│  Matches: Response times under 100ms       │
└────────────────────────────────────────────┘
```

**Less Than or Equal (<=):**
```
Syntax: field:<=value

Examples:
┌────────────────────────────────────────────┐
│  Example 1: INFO and lower logs            │
│  severity:<=3                              │
│                                            │
│  Matches:                                  │
│    ✓ severity: 1, 2, 3                    │
│    ✗ severity: 4, 5                       │
├────────────────────────────────────────────┤
│  Example 2: Successful HTTP responses      │
│  status_code:<=299                         │
│                                            │
│  Matches: 200, 201, 204, etc.              │
└────────────────────────────────────────────┘
```

### Date Range Queries

**Absolute Date Ranges:**
```
Syntax: @timestamp:[start TO end]

Examples:
┌─────────────────────────────────────────────────┐
│  Example 1: Specific date range                 │
│  @timestamp:[2025-11-01 TO 2025-11-30]          │
│                                                 │
│  Matches: All of November 2025                  │
├─────────────────────────────────────────────────┤
│  Example 2: Specific time range                 │
│  @timestamp:[2025-11-01T14:00:00 TO 2025-11-01T15:00:00]│
│                                                 │
│  Matches: 2-3 PM on Nov 1                       │
├─────────────────────────────────────────────────┤
│  Example 3: Open-ended ranges                   │
│  @timestamp:>=2025-11-01                        │
│                                                 │
│  Matches: November 1st onwards                  │
└─────────────────────────────────────────────────┘
```

**Relative Date Ranges:**
```
Syntax: now-<time>/<unit>

Time units:
├─ s = seconds
├─ m = minutes
├─ h = hours
├─ d = days
├─ w = weeks
├─ M = months
└─ y = years

Examples:
┌─────────────────────────────────────────────────┐
│  Last hour:                                     │
│  @timestamp:>=now-1h                            │
├─────────────────────────────────────────────────┤
│  Last 24 hours:                                 │
│  @timestamp:>=now-24h                           │
│  OR                                             │
│  @timestamp:>=now-1d                            │
├─────────────────────────────────────────────────┤
│  Last 7 days:                                   │
│  @timestamp:>=now-7d                            │
│  OR                                             │
│  @timestamp:>=now-1w                            │
├─────────────────────────────────────────────────┤
│  Between 2 and 1 hour ago:                      │
│  @timestamp:[now-2h TO now-1h]                  │
├─────────────────────────────────────────────────┤
│  More than 30 days old:                         │
│  @timestamp:<now-30d                            │
└─────────────────────────────────────────────────┘
```

### Real-World Range Query Examples

**Scenario 1: Find recent errors (last 15 minutes):**
```
Query:
level:ERROR AND @timestamp:>=now-15m

Use Case: Real-time error monitoring
```

**Scenario 2: Find slow API responses:**
```
Query:
response_time:>1000

Explanation: Responses taking more than 1 second
Use Case: Performance optimization
```

**Scenario 3: Find business hours logs:**
```
Query:
@timestamp:[2025-11-01T09:00:00 TO 2025-11-01T17:00:00]

Use Case: Analyze business hours traffic
```

**Scenario 4: Find high-priority issues:**
```
Query:
severity:>=4 AND @timestamp:>=now-1h

Explanation: WARN and ERROR logs from last hour
Use Case: Incident response dashboard
```

**Scenario 5: Find HTTP client errors (4xx):**
```
Query:
status_code:[400 TO 499]

Use Case: Client error analysis
```

---

## Wildcards (Lucene): *, ?

### Understanding Wildcards
```
Wildcard Characters:
┌────────────────────────────────────────┐
│  * (Asterisk)                          │
│  • Matches zero or more characters     │
│  • Can be anywhere in the string       │
│  • Example: user* matches:             │
│    - user                              │
│    - users                             │
│    - userService                       │
│    - user123                           │
├────────────────────────────────────────┤
│  ? (Question Mark)                     │
│  • Matches exactly ONE character       │
│  • Must match a character (not zero)   │
│  • Example: user? matches:             │
│    - user1                             │
│    - userA                             │
│    ✗ user (no character after)        │
│    ✗ user12 (two characters)          │
└────────────────────────────────────────┘
```

### Asterisk (*) - Zero or More Characters

**Basic Usage:**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: All user-related logs          │
│  message:user*                             │
│                                            │
│  Matches:                                  │
│    ✓ "user created"                       │
│    ✓ "users fetched"                      │
│    ✓ "userService started"                │
│    ✓ "user" (exact match also works)      │
├────────────────────────────────────────────┤
│  Example 2: All email addresses            │
│  email:*@example.com                       │
│                                            │
│  Matches:                                  │
│    ✓ john@example.com                     │
│    ✓ admin@example.com                    │
│    ✗ john@gmail.com                       │
├────────────────────────────────────────────┤
│  Example 3: All error types                │
│  message:*Error                            │
│                                            │
│  Matches:                                  │
│    ✓ "NullPointerError"                   │
│    ✓ "DatabaseError"                      │
│    ✓ "ValidationError"                    │
└────────────────────────────────────────────┘
```

**Wildcard Positions:**
```
Beginning: *test
├─ Matches: "unitest", "mytest", "test"

Middle: log*file
├─ Matches: "logfile", "log_file", "log123file"

End: test*
├─ Matches: "test", "testing", "test123"

Multiple: *test*
├─ Matches: anything containing "test"
```

### Question Mark (?) - Exactly One Character

**Basic Usage:**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: Match log levels with pattern  │
│  level:???                                 │
│                                            │
│  Matches (exactly 3 characters):           │
│    ✗ ERROR (5 chars)                      │
│    ✗ WARN (4 chars)                       │
│    ✗ INFO (4 chars)                       │
├────────────────────────────────────────────┤
│  Example 2: User IDs with format user?     │
│  user_id:user?                             │
│                                            │
│  Matches:                                  │
│    ✓ user1                                │
│    ✓ userA                                │
│    ✗ user (no character)                  │
│    ✗ user12 (two characters)              │
├────────────────────────────────────────────┤
│  Example 3: Version numbers                │
│  version:1.0.?                             │
│                                            │
│  Matches:                                  │
│    ✓ 1.0.1                                │
│    ✓ 1.0.9                                │
│    ✗ 1.0.10 (two characters)              │
└────────────────────────────────────────────┘
```

### Combining Wildcards

**Using * and ? together:**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: Email pattern                  │
│  email:???*@example.com                    │
│                                            │
│  Matches:                                  │
│    ✓ john@example.com (4+ chars before @) │
│    ✓ admin@example.com                    │
│    ✗ ab@example.com (only 2 chars)        │
├────────────────────────────────────────────┤
│  Example 2: File extensions                │
│  filename:*.???                            │
│                                            │
│  Matches:                                  │
│    ✓ document.pdf                         │
│    ✓ image.jpg                            │
│    ✗ file.html (4 char extension)         │
├────────────────────────────────────────────┤
│  Example 3: IP address pattern             │
│  ip:192.168.?.???                          │
│                                            │
│  Matches:                                  │
│    ✓ 192.168.1.100                        │
│    ✓ 192.168.5.255                        │
│    ✗ 192.168.10.1 (two digits in 3rd)     │
└────────────────────────────────────────────┘
```

### Real-World Wildcard Examples

**Scenario 1: Find all controller classes:**
```
Query:
class_name:*Controller

Matches:
├─ UserController
├─ ProductController
├─ OrderController
└─ PaymentController

Use Case: Analyze all controller logs
```

**Scenario 2: Find test user activity:**
```
Query:
user_id:test*

Matches:
├─ test1
├─ test_user
├─ testing123
└─ test

Use Case: Filter out test data
```

**Scenario 3: Find all API endpoints under /api/**
```
Query:
http_path:/api/*

Matches:
├─ /api/users
├─ /api/products
├─ /api/orders/123
└─ /api/payment/process

Use Case: API usage analytics
```

**Scenario 4: Find exception stack traces:**
```
Query:
message:*Exception*

Matches:
├─ NullPointerException
├─ SQLException
├─ IllegalArgumentException
└─ "Caught exception: ..."

Use Case: Exception monitoring
```

**Scenario 5: Find database queries:**
```
Query:
message:*SELECT* OR message:*INSERT* OR message:*UPDATE* OR message:*DELETE*

Matches: All SQL query logs
Use Case: Database query analysis
```

### Performance Considerations
```
Wildcard Performance Impact:
┌────────────────────────────────────────────┐
│  FAST (Good Performance):                  │
│  ├─ field:value*  (prefix wildcard)        │
│  └─ field:val*    (starting pattern)       │
├────────────────────────────────────────────┤
│  SLOW (Poor Performance):                  │
│  ├─ field:*value  (leading wildcard)       │
│  ├─ field:*val*   (both sides)             │
│  └─ Reason: Must scan all documents        │
├────────────────────────────────────────────┤
│  Best Practices:                           │
│  ├─ Avoid leading wildcards when possible  │
│  ├─ Use specific prefixes                  │
│  ├─ Combine with other filters to narrow   │
│  └─ Consider using regex for complex patterns│
└────────────────────────────────────────────┘
```

**Optimization Examples:**
```
❌ Slow query:
*Error

✅ Better query:
message:*Error

✅ Even better:
level:ERROR OR message:*Error

✅ Best (if possible):
level:ERROR
```

---

## Regex (Lucene): / [ ] /, / < > /

### Understanding Regex in Lucene
```
Regex Syntax in Lucene:
┌────────────────────────────────────────────┐
│  Format: field:/regex_pattern/             │
│                                            │
│  Must be enclosed in forward slashes: /    │
│  Case-sensitive by default                 │
│  More powerful than wildcards              │
│  Can match complex patterns                │
└────────────────────────────────────────────┘
```

### Basic Regex Patterns

**Character Classes [ ]:**

```
[abc] - Matches any single character: a, b, or c

Examples:
┌────────────────────────────────────────────┐
│  Example 1: Match log levels               │
│  level:/[EW].*/                            │
│                                            │
│  Matches:                                  │
│    ✓ ERROR (starts with E)                │
│    ✓ WARN (starts with W)                 │
│    ✗ INFO (starts with I)                 │
├────────────────────────────────────────────┤
│  Example 2: Match specific digits          │
│  user_id:/user[123]/                       │
│                                            │
│  Matches:                                  │
│    ✓ user1                                │
│    ✓ user2                                │
│    ✓ user3
│ │ ✗ user4 │ │ ✗ user12 │ ├────────────────────────────────────────────┤ │ Example 3: Match vowels │ │ name:/[aeiou].*/ │ │ │ │ Matches: Names starting with vowels │ │ ✓ alice │ │ ✓ oliver │ │ ✗ bob │ └────────────────────────────────────────────┘

```

**Character Ranges:**
```
[a-z] - Lowercase letters
[A-Z] - Uppercase letters
[0-9] - Digits
[a-zA-Z] - Any letter
[a-zA-Z0-9] - Alphanumeric

Examples:
┌────────────────────────────────────────────┐
│  Example 1: User IDs with digits           │
│  user_id:/user[0-9]+/                      │
│                                            │
│  Matches:                                  │
│    ✓ user1                                │
│    ✓ user123                              │
│    ✗ userABC                              │
├────────────────────────────────────────────┤
│  Example 2: Uppercase codes                │
│  code:/[A-Z]{3}/                           │
│                                            │
│  Matches: Exactly 3 uppercase letters      │
│    ✓ ABC                                  │
│    ✓ XYZ                                  │
│    ✗ Ab1                                  │
├────────────────────────────────────────────┤
│  Example 3: Mixed alphanumeric             │
│  session_id:/[a-zA-Z0-9]+/                 │
│                                            │
│  Matches: Any alphanumeric string          │
│    ✓ abc123                               │
│    ✓ XYZ789                               │
│    ✗ abc-123 (contains hyphen)            │
└────────────────────────────────────────────┘
```

**Negated Character Classes [^ ]:**
```
[^abc] - Matches any character EXCEPT a, b, or c

Examples:
┌────────────────────────────────────────────┐
│  Example 1: Non-digit characters           │
│  message:/error[^0-9]+/                    │
│                                            │
│  Matches: "error" followed by non-digits   │
│    ✓ "errorMessage"                       │
│    ✗ "error123"                           │
├────────────────────────────────────────────┤
│  Example 2: Exclude vowels                 │
│  code:/[^aeiou]+/                          │
│                                            │
│  Matches: Strings without vowels           │
│    ✓ "xyz"                                │
│    ✗ "abc"                                │
└────────────────────────────────────────────┘
```

### Quantifiers
```
Quantifier Reference:
┌────────────────────────────────────────────┐
│  + (Plus)                                  │
│  • Matches 1 or more occurrences           │
│  • Example: /a+/ matches: a, aa, aaa       │
├────────────────────────────────────────────┤
│  * (Asterisk)                              │
│  • Matches 0 or more occurrences           │
│  • Example: /a*/ matches: "", a, aa        │
├────────────────────────────────────────────┤
│  ? (Question Mark)                         │
│  • Matches 0 or 1 occurrence               │
│  • Example: /colou?r/ matches: color, colour│
├────────────────────────────────────────────┤
│  {n} (Exact Count)                         │
│  • Matches exactly n occurrences           │
│  • Example: /a{3}/ matches only: aaa       │
├────────────────────────────────────────────┤
│  {n,} (At Least n)                         │
│  • Matches n or more occurrences           │
│  • Example: /a{2,}/ matches: aa, aaa, aaaa │
├────────────────────────────────────────────┤
│  {n,m} (Range)                             │
│  • Matches between n and m occurrences     │
│  • Example: /a{2,4}/ matches: aa, aaa, aaaa│
└────────────────────────────────────────────┘
```

**Quantifier Examples:**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: Phone numbers (digits only)    │
│  phone:/[0-9]{10}/                         │
│                                            │
│  Matches: Exactly 10 digits                │
│    ✓ 1234567890                           │
│    ✗ 123456789 (9 digits)                 │
│    ✗ 12345678901 (11 digits)              │
├────────────────────────────────────────────┤
│  Example 2: Postal codes (5 or 9 digits)   │
│  zip:/[0-9]{5}(-[0-9]{4})?/                │
│                                            │
│  Matches:                                  │
│    ✓ 12345                                │
│    ✓ 12345-6789                           │
│    ✗ 1234                                 │
├────────────────────────────────────────────┤
│  Example 3: Version numbers                │
│  version:/[0-9]+\.[0-9]+\.[0-9]+/          │
│                                            │
│  Matches:                                  │
│    ✓ 1.0.0                                │
│    ✓ 2.5.10                               │
│    ✗ 1.0 (missing patch version)          │
├────────────────────────────────────────────┤
│  Example 4: Words with repeated letters    │
│  message:/(.)\1+/                          │
│                                            │
│  Matches: Any character repeated           │
│    ✓ "success" (cc, ss)                   │
│    ✓ "error" (rr)                         │
│    ✗ "test" (no repeats)                  │
└────────────────────────────────────────────┘
```

### Anchors
```
Anchor Characters:
┌────────────────────────────────────────────┐
│  ^ (Caret)                                 │
│  • Matches start of string                 │
│  • Example: /^ERROR/ matches strings       │
│    starting with "ERROR"                   │
├────────────────────────────────────────────┤
│  $ (Dollar)                                │
│  • Matches end of string                   │
│  • Example: /Error$/ matches strings       │
│    ending with "Error"                     │
└────────────────────────────────────────────┘
```

**Anchor Examples:**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: Logs starting with timestamp   │
│  message:/^[0-9]{4}-[0-9]{2}-[0-9]{2}/     │
│                                            │
│  Matches:                                  │
│    ✓ "2025-11-01 Error occurred"          │
│    ✗ "Error on 2025-11-01"                │
├────────────────────────────────────────────┤
│  Example 2: Email validation               │
│  email:/^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$/│
│                                            │
│  Matches valid email addresses             │
│    ✓ john@example.com                     │
│    ✗ @example.com (no username)           │
│    ✗ john@example (no TLD)                │
├────────────────────────────────────────────┤
│  Example 3: Messages ending with "failed"  │
│  message:/failed$/                         │
│                                            │
│  Matches:                                  │
│    ✓ "Login failed"                       │
│    ✓ "Payment failed"                     │
│    ✗ "failed to connect" (not at end)     │
└────────────────────────────────────────────┘
```

### Special Characters and Escaping
```
Special Characters (need escaping with \):
. (dot) - Any character
| (pipe) - OR operator
( ) - Grouping
[ ] - Character class
{ } - Quantifiers
+ * ? - Quantifiers
^ $ - Anchors
\ - Escape character

To match literal characters, escape them:
┌────────────────────────────────────────────┐
│  Match literal dot:                        │
│  /file\.txt/                               │
│  (Not /file.txt/ which matches "file txt") │
├────────────────────────────────────────────┤
│  Match literal question mark:              │
│  /error\?/                                 │
├────────────────────────────────────────────┤
│  Match literal parentheses:                │
│  /method\(\)/                              │
└────────────────────────────────────────────┘
```

### Grouping and Alternation

**Grouping ( ):**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: Repeated groups                │
│  message:/(error|warning){2,}/             │
│                                            │
│  Matches:                                  │
│    ✓ "errorerror"                         │
│    ✓ "errorwarning"                       │
│    ✓ "warningerrorwarning"                │
├────────────────────────────────────────────┤
│  Example 2: Optional groups                │
│  url:/https?:\/\/.+/                       │
│                                            │
│  Matches:                                  │
│    ✓ http://example.com                   │
│    ✓ https://example.com                  │
│    ✗ ftp://example.com                    │
└────────────────────────────────────────────┘
```

**Alternation (|):**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: Multiple log levels            │
│  level:/(ERROR|WARN|FATAL)/                │
│                                            │
│  Matches:                                  │
│    ✓ ERROR                                │
│    ✓ WARN                                 │
│    ✓ FATAL                                │
│    ✗ INFO                                 │
├────────────────────────────────────────────┤
│  Example 2: HTTP methods                   │
│  http_method:/(POST|PUT|DELETE|PATCH)/     │
│                                            │
│  Matches: All modification methods         │
├────────────────────────────────────────────┤
│  Example 3: File extensions                │
│  filename:/.*\.(jpg|png|gif|jpeg)/         │
│                                            │
│  Matches:                                  │
│    ✓ image.jpg                            │
│    ✓ photo.png                            │
│    ✗ document.pdf                         │
└────────────────────────────────────────────┘
```

### Real-World Regex Examples

**Scenario 1: Find IP addresses:**
```
Query:
message:/\b([0-9]{1,3}\.){3}[0-9]{1,3}\b/

Explanation:
├─ \b - Word boundary
├─ [0-9]{1,3} - 1-3 digits
├─ \. - Literal dot (escaped)
├─ {3} - Repeat 3 times (for first 3 octets)
└─ [0-9]{1,3} - Last octet

Matches:
├─ 192.168.1.1
├─ 10.0.0.255
└─ 172.16.0.1

Use Case: Security log analysis, IP tracking
```

**Scenario 2: Find email addresses:**
```
Query:
email:/[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/

Explanation:
├─ [a-zA-Z0-9._%+-]+ - Username part
├─ @ - Literal @
├─ [a-zA-Z0-9.-]+ - Domain name
├─ \. - Literal dot
└─ [a-zA-Z]{2,} - TLD (2+ letters)

Matches:
├─ john.doe@example.com
├─ admin+test@subdomain.example.org
└─ user_123@my-domain.co.uk

Use Case: PII detection, user activity tracking
```

**Scenario 3: Find error codes:**
```
Query:
message:/E[RR|RROR]-[0-9]{4}/

Explanation:
├─ E[RR|RROR] - Matches "ERR" or "ERROR"
├─ - - Literal hyphen
└─ [0-9]{4} - Exactly 4 digits

Matches:
├─ ERR-1234
├─ ERROR-5678
└─ ERR-0001

Use Case: Error categorization, incident tracking
```

**Scenario 4: Find timestamps in ISO format:**
```
Query:
@timestamp:/[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}/

Explanation:
├─ [0-9]{4} - Year
├─ [0-9]{2} - Month
├─ [0-9]{2} - Day
├─ T - Literal T separator
├─ [0-9]{2}:[0-9]{2}:[0-9]{2} - Time

Matches:
├─ 2025-11-01T14:35:21
├─ 2025-12-31T23:59:59

Use Case: Log parsing, timestamp validation
```

**Scenario 5: Find SQL injection attempts:**
```
Query:
message:/(union.*select|drop.*table|exec.*xp_|<script>)/i

Explanation:
├─ union.*select - SQL UNION attack
├─ drop.*table - Table deletion
├─ exec.*xp_ - Stored procedure execution
└─ <script> - XSS attempt

Note: /i flag for case-insensitive (if supported)

Matches:
├─ "UNION SELECT * FROM users"
├─ "DROP TABLE users"
├─ "<script>alert('xss')</script>"

Use Case: Security monitoring, attack detection
```

**Scenario 6: Find credit card numbers (PCI compliance):**
```
Query:
message:/\b[0-9]{4}[-\s]?[0-9]{4}[-\s]?[0-9]{4}[-\s]?[0-9]{4}\b/

Explanation:
├─ \b - Word boundary
├─ [0-9]{4} - 4 digits
├─ [-\s]? - Optional hyphen or space
└─ Repeat pattern

Matches:
├─ 4532-1234-5678-9012
├─ 4532 1234 5678 9012
├─ 4532123456789012

Use Case: PCI compliance, sensitive data detection
```

**Scenario 7: Find UUID patterns:**
```
Query:
id:/[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}/

Explanation:
├─ [0-9a-f]{8} - 8 hex characters
├─ - - Hyphens as separators
├─ Pattern: 8-4-4-4-12

Matches:
├─ 550e8400-e29b-41d4-a716-446655440000
├─ 6ba7b810-9dad-11d1-80b4-00c04fd430c8

Use Case: Request tracking, correlation IDs
```

**Scenario 8: Find URLs:**
```
Query:
message:/https?:\/\/[a-zA-Z0-9\-\.]+\.[a-zA-Z]{2,}(:[0-9]+)?(\/[^\s]*)?/

Explanation:
├─ https? - HTTP or HTTPS
├─ :\/\/ - ://
├─ [a-zA-Z0-9\-\.]+ - Domain
├─ \.[a-zA-Z]{2,} - TLD
├─ (:[0-9]+)? - Optional port
└─ (\/[^\s]*)? - Optional path

Matches:
├─ https://example.com
├─ http://example.com:8080
├─ https://example.com/api/users

Use Case: URL tracking, external service monitoring
```

### Regex Performance Tips
```
Performance Best Practices:
┌────────────────────────────────────────────┐
│  ✅ DO:                                     │
│  ├─ Use anchors (^ $) when possible        │
│  ├─ Be specific with character classes     │
│  ├─ Use {n,m} instead of + or * when count │
│  │   is known                              │
│  └─ Combine regex with field filters       │
├────────────────────────────────────────────┤
│  ❌ DON'T:                                  │
│  ├─ Use .* at the beginning                │
│  ├─ Create overly complex patterns         │
│  ├─ Use regex for simple wildcard cases    │
│  └─ Forget to escape special characters    │
└────────────────────────────────────────────┘

Example - Optimize this:
❌ Slow:
message:/.*error.*/

✅ Better:
message:/error/
OR
message:*error*

✅ Best (if field exists):
level:ERROR
```

---

## Boolean Operators (KQL): AND, OR, AND NOT

### KQL Syntax Overview
```
KQL vs Lucene Differences:
┌────────────────────────────────────────────┐
│  KQL (Kibana Query Language)               │
│  ├─ Simpler, more intuitive                │
│  ├─ Case-insensitive by default            │
│  ├─ Uses "AND NOT" instead of "NOT"        │
│  ├─ Field names are case-sensitive         │
│  └─ More forgiving with spaces             │
├────────────────────────────────────────────┤
│  Lucene                                    │
│  ├─ More powerful and flexible             │
│  ├─ Case-sensitive for some operators      │
│  ├─ Uses "NOT" or "-"                      │
│  ├─ Requires precise syntax                │
│  └─ Supports regex and complex queries     │
└────────────────────────────────────────────┘
```

### AND Operator (KQL)

**Syntax: Both conditions must be true**
```
field:value AND field:value
OR
field:value and field:value (case-insensitive)

Examples:
┌────────────────────────────────────────────┐
│  Example 1: ERROR logs from UserController │
│  level:ERROR AND class_name:UserController │
│  OR                                        │
│  level:ERROR and class_name:UserController │
│                                            │
│  Both work the same in KQL!                │
├────────────────────────────────────────────┤
│  Example 2: POST requests with errors      │
│  http_method:POST and level:ERROR          │
│                                            │
│  Matches:                                  │
│    ✓ POST + ERROR                         │
│    ✗ POST + INFO                          │
│    ✗ GET + ERROR                          │
├────────────────────────────────────────────┤
│  Example 3: Multiple conditions            │
│  level:ERROR and service_name:"user-service" and @timestamp > "2025-11-01"│
│                                            │
│  All three conditions must match           │
└────────────────────────────────────────────┘
```

**Real-World KQL Examples:**
```
Use Case 1: Recent errors from production
level:ERROR and environment:production and @timestamp > now-1h

Use Case 2: Failed payment transactions
http_path:"/api/payment" and level:ERROR and status_code >= 500

Use Case 3: Specific user's activity
user_id:12345 and level:INFO and message:"login"
```

### OR Operator (KQL)

**Syntax: At least one condition must be true**
```
field:value OR field:value
OR
field:value or field:value (case-insensitive)

Examples:
┌────────────────────────────────────────────┐
│  Example 1: All problematic logs           │
│  level:ERROR or level:WARN                 │
│                                            │
│  Matches:                                  │
│    ✓ level=ERROR                          │
│    ✓ level=WARN                           │
│    ✗ level=INFO                           │
├────────────────────────────────────────────┤
│  Example 2: Multiple services              │
│  service_name:"user-service" or service_name:"auth-service"│
│                                            │
│  Matches logs from either service          │
├────────────────────────────────────────────┤
│  Example 3: Multiple HTTP methods          │
│  http_method:POST or http_method:PUT or http_method:DELETE│
│                                            │
│  Matches: All modification requests        │
└────────────────────────────────────────────┘
```

**Real-World KQL Examples:**
```
Use Case 1: All critical issues
level:ERROR or level:FATAL or message:critical

Use Case 2: Authentication events
message:login or message:logout or message:authentication

Use Case 3: Multiple endpoints
http_path:"/api/users" or http_path:"/api/products" or http_path:"/api/orders"
```

### AND NOT Operator (KQL)

**Important: KQL uses "AND NOT" not just "NOT"**
```
Syntax: Exclude matching documents
field:value AND NOT field:value

Examples:
┌────────────────────────────────────────────┐
│  Example 1: All logs except DEBUG          │
│  * AND NOT level:DEBUG                     │
│  (* matches everything)                    │
│                                            │
│  Matches:                                  │
│    ✓ level=INFO                           │
│    ✓ level=ERROR                          │
│    ✗ level=DEBUG                          │
├────────────────────────────────────────────┤
│  Example 2: Exclude health checks          │
│  * AND NOT http_path:"/health"             │
│                                            │
│  Matches: All requests except /health      │
├────────────────────────────────────────────┤
│  Example 3: Production without test users  │
│  environment:production AND NOT user_id:test*│
│                                            │
│  Matches: Real user activity only          │
└────────────────────────────────────────────┘
```

**Real-World KQL Examples:**
```
Use Case 1: Errors excluding known issues
level:ERROR AND NOT message:"timeout"

Use Case 2: All services except monitoring
* AND NOT service_name:"monitoring-service"

Use Case 3: API calls excluding internal
http_path:"/api/*" AND NOT user_agent:"internal-service"
```

### Combining Operators in KQL

**Using Parentheses for Complex Queries:**
```
Examples:
┌─────────────────────────────────────────────────┐
│  Example 1: Errors or warnings from production  │
│  (level:ERROR or level:WARN) and environment:production│
│                                                 │
│  Breakdown:                                     │
│  ├─ (level:ERROR or level:WARN) evaluated first│
│  └─ Then filtered by environment               │
├─────────────────────────────────────────────────┤
│  Example 2: Modifications excluding test users  │
│  (http_method:POST or http_method:PUT or http_method:DELETE) AND NOT user_id:test*│
│                                                 │
│  Matches: Real user modifications only          │
├─────────────────────────────────────────────────┤
│  Example 3: Multiple services with errors       │
│  (service_name:"user-service" or service_name:"payment-service") and level:ERROR│
│                                                 │
│  Matches: Errors from specific services only    │
└─────────────────────────────────────────────────┘
```

**Complex Real-World Scenario:**
```
Business Requirement:
"Find all failed payment transactions from the last hour,
 excluding test users, in production environment"

KQL Query:
http_path:"/api/payment" 
and level:ERROR 
and environment:production 
and @timestamp > now-1h 
AND NOT user_id:test*

Breakdown:
├─ http_path:"/api/payment" - Payment endpoint only
├─ level:ERROR - Failed transactions
├─ environment:production - Production only
├─ @timestamp > now-1h - Last hour
└─ AND NOT user_id:test* - Exclude test users
```

---

## Search By Field (KQL)

### Basic Field Search
```
Syntax: fieldname:value

KQL Field Search Features:
├─ Case-insensitive field values (ERROR = error)
├─ Case-SENSITIVE field names (level ≠ Level)
├─ Auto-complete suggestions
└─ More forgiving with special characters

Examples:
┌────────────────────────────────────────────┐
│  Example 1: Search by log level            │
│  level:error     (matches ERROR, Error)    │
│  level:ERROR     (same result)             │
│  level:Error     (same result)             │
│                                            │
│  Note: Field VALUE is case-insensitive     │
├────────────────────────────────────────────┤
│  Example 2: Search by class name           │
│  class_name:UserController                 │
│  class_name:usercontroller  (same result)  │
├────────────────────────────────────────────┤
│  Example 3: Search by HTTP method          │
│  http_method:get                           │
│  http_method:GET  (same result)            │
└────────────────────────────────────────────┘
```

### Field Search with Quotes
```
Use quotes for phrases or values with spaces:

With quotes (exact phrase):
message:"User not found"
└─ Matches only the exact phrase

Without quotes:
message:User not found
└─ Interpreted as: message:User AND message:not AND message:found

Examples:
┌────────────────────────────────────────────┐
│  Example 1: Service names with spaces      │
│  service_name:"user authentication service"│
│  ✓ Correct                                │
│                                            │
│  service_name:user authentication service  │
│  ✗ Wrong - searches for 3 separate words  │
├────────────────────────────────────────────┤
│  Example 2: Messages with multiple words   │
│  message:"database connection failed"      │
│  ✓ Exact phrase match                     │
│                                            │
│  message:database connection failed        │
│  ✗ Matches ANY of these words             │
└────────────────────────────────────────────┘
```

### Multiple Field Searches
```
Combine multiple field searches:

Example 1: Specific log entry
level:ERROR and class_name:UserController and user_id:123

Example 2: API monitoring
http_method:POST and http_path:"/api/users" and status_code:201

Example 3: Service health
service_name:"payment-service" and level:ERROR and message:timeout
```

---

## Free Text (KQL)

### Basic Free Text Search
```
Just type the text - searches across all fields

KQL Free Text Features:
├─ Case-insensitive
├─ Searches all indexed fields
├─ Matches partial words
└─ Simple and intuitive

Examples:
┌────────────────────────────────────────────┐
│  Example 1: Search for "error"             │
│  error                                     │
│                                            │
│  Searches in ALL fields:                   │
│    • level: "ERROR"                       │
│    • message: "Database error occurred"    │
│    • stack_trace: "NullPointerError"       │
│    • class_name: "ErrorHandler"            │
├────────────────────────────────────────────┤
│  Example 2: Search for user-related logs   │
│  user                                      │
│                                            │
│  Matches:                                  │
│    • message: "User created"              │
│    • service_name: "user-service"          │
│    • class_name: "UserController"          │
│    • user_id: "user123"                    │
├────────────────────────────────────────────┤
│  Example 3: Search for payment info        │
│  payment                                   │
│                                            │
│  Finds all payment-related logs            │
└────────────────────────────────────────────┘
```

### Free Text with Phrases
```
Use quotes for exact phrase matching:

Exact phrase:
"User not found"
└─ Matches only this exact phrase

Multiple words without quotes:
User not found
└─ Matches logs containing ANY of these words

Examples:
┌────────────────────────────────────────────┐
│  Example 1: Exact error message            │
│  "database connection timeout"             │
│  ✓ Matches: "database connection timeout"  │
│  ✗ Does not match: "database timeout"     │
├────────────────────────────────────────────┤
│  Example 2: Multiple words                 │
│  database connection timeout               │
│  ✓ Matches: "database error"              │
│  ✓ Matches: "connection failed"           │
│  ✓ Matches: "timeout occurred"            │
│                                            │
│  Searches for ANY of the words             │
└────────────────────────────────────────────┘
```

### Combining Free Text with Field Searches
```
Mix free text and field searches:

Example 1: Errors containing "payment"
level:ERROR and payment

Example 2: Recent logs about users
user and @timestamp > now-1h

Example 3: Service-specific free text
service_name:"order-service" and "inventory check"
```

---

## Ranges (KQL): >, >=, <, <=

### KQL Range Operators
```
KQL Range Operators (Simpler than Lucene):
┌────────────────────────────────────────────┐
│  > (Greater than)                          │
│  >= (Greater than or equal)                │
│  < (Less than)                             │
│  <= (Less than or equal)                   │
│                                            │
│  No need for brackets [ ] or braces { }    │
│  Just use the operators directly!          │
└────────────────────────────────────────────┘
```

### Numeric Ranges in KQL

**Greater Than (>):**
```
┌────────────────────────────────────────────┐ │ Example 1: High severity logs │ │ severity > 3 │ │ │ │ Matches: │ │ ✓ severity: 4 (WARN) │ │ ✓ severity: 5 (ERROR) │ │ ✗ severity: 3 (INFO) │ ├────────────────────────────────────────────┤ │ Example 2: Large response times │ │ response_time > 1000 │ │ │ │ Matches: Responses over 1 second │ ├────────────────────────────────────────────┤ │ Example 3: High user IDs │ │ user_id > 1000 │ │ │ │ Matches: User IDs above 1000 │ └────────────────────────────────────────────┘

```

**Greater Than or Equal (>=):**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: Warnings and errors            │
│  severity >= 4                             │
│                                            │
│  Matches:                                  │
│    ✓ severity: 4 (WARN)                   │
│    ✓ severity: 5 (ERROR)                  │
│    ✗ severity: 3 (INFO)                   │
├────────────────────────────────────────────┤
│  Example 2: HTTP errors (4xx, 5xx)         │
│  status_code >= 400                        │
│                                            │
│  Matches: 400, 404, 500, etc.              │
├────────────────────────────────────────────┤
│  Example 3: Active users                   │
│  login_count >= 1                          │
│                                            │
│  Matches: Users who logged in at least once│
└────────────────────────────────────────────┘
```

**Less Than (<):**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: Low severity logs              │
│  severity < 3                              │
│                                            │
│  Matches:                                  │
│    ✓ severity: 1 (TRACE)                  │
│    ✓ severity: 2 (DEBUG)                  │
│    ✗ severity: 3 (INFO)                   │
├────────────────────────────────────────────┤
│  Example 2: Fast responses                 │
│  response_time < 100                       │
│                                            │
│  Matches: Responses under 100ms            │
├────────────────────────────────────────────┤
│  Example 3: Low traffic                    │
│  request_count < 1000                      │
│                                            │
│  Matches: Low request volumes              │
└────────────────────────────────────────────┘
```

**Less Than or Equal (<=):**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: Info and lower                 │
│  severity <= 3                             │
│                                            │
│  Matches:                                  │
│    ✓ severity: 1, 2, 3                    │
│    ✗ severity: 4, 5                       │
├────────────────────────────────────────────┤
│  Example 2: Successful HTTP responses      │
│  status_code <= 299                        │
│                                            │
│  Matches: 200, 201, 204, etc.              │
├────────────────────────────────────────────┤
│  Example 3: Small file sizes               │
│  file_size <= 1048576                      │
│                                            │
│  Matches: Files 1MB or smaller             │
└────────────────────────────────────────────┘
```

### Date/Time Ranges in KQL

**Relative Time Ranges:**
```
Syntax: @timestamp > now-<duration>

Time units (same as Lucene):
├─ s = seconds
├─ m = minutes
├─ h = hours
├─ d = days
├─ w = weeks
├─ M = months
└─ y = years

Examples:
┌────────────────────────────────────────────┐
│  Example 1: Last hour                      │
│  @timestamp > now-1h                       │
│  OR                                        │
│  @timestamp >= now-1h                      │
├────────────────────────────────────────────┤
│  Example 2: Last 24 hours                  │
│  @timestamp > now-24h                      │
│  OR                                        │
│  @timestamp > now-1d                       │
├────────────────────────────────────────────┤
│  Example 3: Last week                      │
│  @timestamp > now-7d                       │
│  OR                                        │
│  @timestamp > now-1w                       │
├────────────────────────────────────────────┤
│  Example 4: Last 30 minutes                │
│  @timestamp > now-30m                      │
├────────────────────────────────────────────┤
│  Example 5: More than 1 day old            │
│  @timestamp < now-1d                       │
└────────────────────────────────────────────┘
```

**Absolute Date Ranges:**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: After specific date            │
│  @timestamp > "2025-11-01"                 │
│                                            │
│  Matches: All logs after Nov 1, 2025       │
├────────────────────────────────────────────┤
│  Example 2: Before specific date           │
│  @timestamp < "2025-11-30"                 │
│                                            │
│  Matches: All logs before Nov 30, 2025     │
├────────────────────────────────────────────┤
│  Example 3: Specific time range            │
│  @timestamp >= "2025-11-01T00:00:00" and @timestamp <= "2025-11-01T23:59:59"│
│                                            │
│  Matches: All of November 1st, 2025        │
└────────────────────────────────────────────┘
```

### Combining Range Operators

**Multiple Range Conditions:**
```
Example 1: Medium severity logs (WARN only)
severity >= 4 and severity < 5

Example 2: Normal HTTP responses (2xx and 3xx)
status_code >= 200 and status_code < 400

Example 3: Recent slow requests
@timestamp > now-1h and response_time > 1000

Example 4: Specific time window
@timestamp >= "2025-11-01T09:00:00" and @timestamp <= "2025-11-01T17:00:00"
```

### Real-World KQL Range Examples

**Scenario 1: Performance monitoring - slow API calls:**
```
Query:
http_path:"/api/*" and response_time > 2000 and @timestamp > now-1h

Explanation:
├─ API endpoints only
├─ Responses slower than 2 seconds
└─ In the last hour

Use Case: Identify performance bottlenecks
```

**Scenario 2: Error spike detection:**
```
Query:
level:ERROR and @timestamp > now-15m

Explanation:
├─ Only error logs
└─ Last 15 minutes

Use Case: Real-time error monitoring
```

**Scenario 3: User activity analysis:**
```
Query:
user_id > 1000 and user_id < 2000 and @timestamp > now-7d

Explanation:
├─ Specific user ID range
└─ Last 7 days

Use Case: Cohort analysis
```

**Scenario 4: HTTP error tracking:**
```
Query:
status_code >= 400 and status_code < 600 and @timestamp > now-1h

Explanation:
├─ All HTTP error codes (4xx and 5xx)
└─ Last hour

Use Case: Monitor service health
```

**Scenario 5: High-value transactions:**
```
Query:
http_path:"/api/payment" and transaction_amount >= 1000 and @timestamp > now-24h

Explanation:
├─ Payment endpoint
├─ Transactions of $1000 or more
└─ Last 24 hours

Use Case: Financial monitoring
```

---

## Wildcard (KQL): *

### KQL Wildcard Syntax
```
KQL Wildcard Features:
┌────────────────────────────────────────────┐
│  * (Asterisk)                              │
│  • Matches zero or more characters         │
│  • Can be used at beginning, middle, or end│
│  • Case-insensitive                        │
│  • Simpler than Lucene wildcards           │
│                                            │
│  Note: KQL does NOT support ? wildcard     │
│  (Only * is available)                     │
└────────────────────────────────────────────┘
```

### Basic Wildcard Usage

**Prefix Wildcard (ends with *):**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: All user-related               │
│  message:user*                             │
│                                            │
│  Matches:                                  │
│    ✓ "user"                               │
│    ✓ "users"                              │
│    ✓ "userService"                        │
│    ✓ "user123"                            │
│    ✗ "theuser" (doesn't start with user)  │
├────────────────────────────────────────────┤
│  Example 2: All services                   │
│  service_name:*service                     │
│                                            │
│  Matches:                                  │
│    ✓ "user-service"                       │
│    ✓ "payment-service"                    │
│    ✓ "order-service"                      │
├────────────────────────────────────────────┤
│  Example 3: Email domain                   │
│  email:*@example.com                       │
│                                            │
│  Matches:                                  │
│    ✓ john@example.com                     │
│    ✓ admin@example.com                    │
│    ✗ john@gmail.com                       │
└────────────────────────────────────────────┘
```

**Suffix Wildcard (starts with *):**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: All error types                │
│  message:*Error                            │
│                                            │
│  Matches:                                  │
│    ✓ "NullPointerError"                   │
│    ✓ "DatabaseError"                      │
│    ✓ "ValidationError"                    │
│    ✓ "Error" (exact match works too)      │
├────────────────────────────────────────────┤
│  Example 2: All exceptions                 │
│  class_name:*Exception                     │
│                                            │
│  Matches:                                  │
│    ✓ "RuntimeException"                   │
│    ✓ "SQLException"                       │
│    ✓ "IllegalArgumentException"           │
└────────────────────────────────────────────┘
```

**Middle Wildcard (both ends specified):**
```
Examples:
┌────────────────────────────────────────────┐
│  Example 1: Contains "error"               │
│  message:*error*                           │
│                                            │
│  Matches:                                  │
│    ✓ "An error occurred"                  │
│    ✓ "errorHandler started"               │
│    ✓ "System error detected"              │
│    ✓ "error" (exact match)                │
├────────────────────────────────────────────┤
│  Example 2: Contains "connection"          │
│  message:*connection*                      │
│                                            │
│  Matches:                                  │
│    ✓ "database connection failed"         │
│    ✓ "connection timeout"                 │
│    ✓ "new connection established"         │
└────────────────────────────────────────────┘
```

### Wildcard with Multiple Fields
```
Combine wildcards with field searches:

Example 1: Test users in production
user_id:test* and environment:production

Example 2: All controllers with errors
class_name:*Controller and level:ERROR

Example 3: API endpoints with failures
http_path:/api/* and status_code >= 400

Example 4: Email domain analysis
email:*@example.com and @timestamp > now-7d
```

### Real-World KQL Wildcard Examples

**Scenario 1: Find all microservice logs:**
```
Query:
service_name:*-service and level:ERROR

Explanation:
├─ Matches: user-service, payment-service, etc.
└─ Only error logs

Use Case: Cross-service error monitoring
```

**Scenario 2: Track test data:**
```
Query:
user_id:test* or email:test*@*

Explanation:
├─ User IDs starting with "test"
└─ Email addresses starting with "test"

Use Case: Filter out test data from analytics
```

**Scenario 3: API versioning analysis:**
```
Query:
http_path:/api/v* and @timestamp > now-30d

Explanation:
├─ Matches: /api/v1/*, /api/v2/*, etc.
└─ Last 30 days

Use Case: Track API version usage
```

**Scenario 4: Exception handling monitoring:**
```
Query:
message:*Exception* and level:ERROR and @timestamp > now-1h

Explanation:
├─ Any exception type
├─ Error level only
└─ Last hour

Use Case: Exception tracking dashboard
```

**Scenario 5: File operation logs:**
```
Query:
message:*file* and (message:*read* or message:*write* or message:*delete*)

Explanation:
├─ Logs containing "file"
└─ With read, write, or delete operations

Use Case: File system activity monitoring
```

**Scenario 6: Authentication pattern matching:**
```
Query:
message:*authentication* or message:*login* or message:*logout*

Explanation:
└─ All authentication-related activities

Use Case: Security audit trail
```

---

## Conclusion

### Summary of ELK Stack Benefits
```
┌───────────────────────────────────────────────────┐
│  What You've Learned:                             │
├───────────────────────────────────────────────────┤
│                                                   │
│  1. ELK Stack Components:                         │
│     ├─ Elasticsearch: Storage & Search Engine    │
│     ├─ Logstash: Log Processing Pipeline         │
│     └─ Kibana: Visualization & Dashboard         │
│                                                   │
│  2. Real-World Benefits:                          │
│     ├─ Centralized logging across services       │
│     ├─ Real-time monitoring & alerting           │
│     ├─ Fast troubleshooting (hours → minutes)    │
│     ├─ Business intelligence from logs           │
│     └─ Scalable architecture                     │
│                                                   │
│  3. Query Languages:                              │
│     ├─ Lucene: Powerful, complex queries         │
│     └─ KQL: Simple, user-friendly syntax         │
│                                                   │
│  4. Search Capabilities:                          │
│     ├─ Field searches                            │
│     ├─ Boolean operators (AND, OR, NOT)          │
│     ├─ Range queries                             │
│     ├─ Wildcards                                 │
│     └─ Regular expressions                       │
│                                                   │
└───────────────────────────────────────────────────┘
```

### Best Practices Summary

**1. Logging Best Practices:**
```
✅ DO:
├─ Use structured logging (JSON format)
├─ Include correlation IDs for request tracking
├─ Log at appropriate levels (DEBUG, INFO, WARN, ERROR)
├─ Include contextual information (user_id, service_name)
├─ Use consistent field names across services
└─ Implement log rotation policies

❌ DON'T:
├─ Log sensitive data (passwords, credit cards, SSNs)
├─ Log excessively (kills performance and storage)
├─ Use inconsistent timestamp formats
├─ Forget to log exceptions with stack traces
└─ Mix different log formats in same system
```

**2. Elasticsearch Best Practices:**
```
✅ DO:
├─ Set appropriate heap size (50% of RAM, max 32GB)
├─ Use index lifecycle management (ILM)
├─ Monitor cluster health regularly
├─ Use time-based indices (daily/weekly)
├─ Set up proper backup/restore procedures
└─ Optimize index mappings for your data

❌ DON'T:
├─ Store all data in single index
├─ Ignore disk space warnings
├─ Run without monitoring
├─ Use default settings in production
└─ Forget to set retention policies
```

**3. Kibana Query Best Practices:**
```
✅ DO:
├─ Start with simple queries, then add complexity
├─ Use field filters when possible (faster than free text)
├─ Leverage saved searches for common queries
├─ Create dashboards for monitoring
├─ Use time range filters to narrow results
└─ Combine multiple conditions with parentheses

❌ DON'T:
├─ Use leading wildcards (*term) - very slow
├─ Query without time range filters
├─ Over-complicate queries unnecessarily
├─ Forget to save useful queries
└─ Ignore query performance
```

**4. Logstash Best Practices:**
```
✅ DO:
├─ Test grok patterns before deploying
├─ Use conditional processing to optimize
├─ Implement proper error handling
├─ Monitor Logstash performance
├─ Use appropriate worker settings
└─ Version control your configurations

❌ DON'T:
├─ Process all logs identically
├─ Ignore parsing errors
├─ Over-complicate filter chains
├─ Forget to handle exceptions
└─ Skip configuration testing
```

### Production Checklist
```
Before Going Live:
□ Security configured (authentication, SSL/TLS)
□ Backup and restore tested
□ Monitoring and alerting set up
□ Index lifecycle management configured
□ Log retention policies defined
□ Disk space monitoring enabled
□ Performance baselines established
□ Documentation completed
□ Team trained on query syntax
□ Runbooks created for common issues
```

### Common Use Cases Recap

**1. Application Performance Monitoring (APM):**
```
Query: response_time > 1000 and @timestamp > now-1h
Use: Identify slow endpoints
```

**2. Error Tracking:**
```
Query: level:ERROR and @timestamp > now-15m
Use: Real-time error monitoring
```

**3. Security Monitoring:**
```
Query: message:*authentication* and level:WARN
Use: Track failed login attempts
```

**4. Business Analytics:**
```
Query: http_path:"/api/checkout" and status_code:200
Use: Track successful transactions
```

**5. Infrastructure Monitoring:**
```
Query: service_name:* and level:ERROR
Use: Service health dashboard
```

### Performance Optimization Tips
```
Query Performance Hierarchy (Fastest to Slowest):
┌────────────────────────────────────────────┐
│  1. Field exact match                      │
│     level:ERROR                            │
│     ⚡ Fastest - uses inverted index       │
├────────────────────────────────────────────┤
│  2. Field with prefix wildcard             │
│     message:user*                          │
│     ⚡⚡ Fast - prefix optimization         │
├────────────────────────────────────────────┤
│  3. Range queries                          │
│     @timestamp > now-1h                    │
│     ⚡⚡⚡ Good - indexed ranges             │
├────────────────────────────────────────────┤
│  4. Multiple field combinations            │
│     level:ERROR and service_name:"user"    │
│     ⚡⚡⚡ Good - combines efficient queries │
├────────────────────────────────────────────┤
│  5. Suffix/middle wildcards                │
│     message:*error* or message:*Error      │
│     🐌 Slow - must scan documents          │
├────────────────────────────────────────────┤
│  6. Free text search                       │
│     error                                  │
│     🐌🐌 Slower - searches all fields      │
├────────────────────────────────────────────┤
│  7. Regex patterns                         │
│     message:/.*error.*/                    │
│     🐌🐌🐌 Slowest - complex matching      │
└────────────────────────────────────────────┘
```

### Next Steps and Advanced Topics

**To Continue Your Journey:**
```
1. Advanced Elasticsearch:
   ├─ Cluster management and scaling
   ├─ Custom analyzers and tokenizers
   ├─ Aggregations and analytics
   ├─ Machine learning anomaly detection
   └─ Cross-cluster search

2. Advanced Logstash:
   ├─ Custom plugins development
   ├─ Multiple pipeline configuration
   ├─ Performance tuning
   ├─ Integration with message queues
   └─ Data enrichment techniques

3. Advanced Kibana:
   ├─ Custom visualizations
   ├─ Canvas for infographics
   ├─ Machine learning jobs
   ├─ Alerting and actions
   └─ Reporting and PDF generation

4. ELK Security:
   ├─ X-Pack security features
   ├─ Role-based access control (RBAC)
   ├─ Audit logging
   ├─ Encryption at rest and in transit
   └─ SIEM capabilities

5. Observability Stack:
   ├─ APM (Application Performance Monitoring)
   ├─ Uptime monitoring
   ├─ Metrics (Metricbeat)
   ├─ Distributed tracing
   └─ Infrastructure monitoring
```

### Troubleshooting Quick Reference

**Common Issues and Solutions:**
```
Issue 1: No data appearing in Kibana
├─ Check: Is Elasticsearch running? (curl localhost:9200)
├─ Check: Is Logstash processing? (Look for pipeline started)
├─ Check: Is Spring Boot writing logs? (Check logs/ directory)
├─ Check: Is file path correct in logstash.conf?
└─ Solution: Verify each component step by step

Issue 2: Slow queries
├─ Check: Are you using leading wildcards? (*term)
├─ Check: Is time range too broad?
├─ Check: Is cluster under heavy load?
└─ Solution: Optimize query, add time filters, scale cluster

Issue 3: Out of disk space
├─ Check: Index sizes (GET /_cat/indices?v)
├─ Check: Old indices (set up ILM)
├─ Solution: Delete old indices, implement retention policy

Issue 4: High memory usage
├─ Check: JVM heap size configuration
├─ Check: Number of shards and replicas
├─ Solution: Adjust heap, optimize shard allocation

Issue 5: Logstash not parsing logs correctly
├─ Check: Grok pattern syntax
├─ Check: Sample log format matches pattern
├─ Solution: Test in Grok Debugger, fix pattern
```

### Resources and Documentation
```
Official Documentation:
├─ Elasticsearch: https://www.elastic.co/guide/en/elasticsearch/
├─ Logstash: https://www.elastic.co/guide/en/logstash/
├─ Kibana: https://www.elastic.co/guide/en/kibana/
└─ Elastic Blog: https://www.elastic.co/blog/

Community Resources:
├─ Elastic Forums: https://discuss.elastic.co/
├─ Stack Overflow: [elasticsearch] [logstash] [kibana] tags
├─ GitHub: https://github.com/elastic/
└─ Elastic Community Slack

Learning Resources:
├─ Elastic Certified Engineer Training
├─ Elastic YouTube Channel
├─ Free Elastic Webinars
└─ Hands-on Labs and Workshops
```

### Final Thoughts
```

┌─────────────────────────────────────────────────┐ │ Key Takeaways: │ ├─────────────────────────────────────────────────┤ │ │ │ 1. ELK Stack transforms chaos into clarity │ │ Hours of debugging → Minutes of analysis │ │ │ │ 2. Centralized logging is not optional │ │ Modern applications NEED observability │ │ │ │ 3. Start simple, scale as needed │ │ Single node → Multi-node cluster │ │ │ │ 4. Query mastery comes with practice │ │ Start with field searches → Advanced regex │ │ │ │ 5. Monitoring saves money and reputation │ │ Proactive detection > Reactive firefighting │ │ │ │ "You can't improve what you can't measure" │ │ "Logs are your application's story" │ │ "ELK Stack is your storytelling platform" │ │ │ └─────────────────────────────────────────────────┘

```

---

**Congratulations!** 🎉

You've completed this comprehensive ELK Stack tutorial. You now have the knowledge to:
- Set up and configure ELK Stack
- Monitor Spring Boot microservices effectively
- Write powerful queries in both Lucene and KQL
- Troubleshoot production issues quickly
- Build real-time monitoring dashboards

**Remember:** The best way to learn is by doing. Start small, experiment with different queries, and gradually build more complex monitoring solutions.

Happy Logging! 📊🔍🚀

